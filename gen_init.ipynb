{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "#!python -m pip install networkx\n",
        "#!python -m pip install matplotlib==2.2.3\n",
        "#!python -m pip install ipywidgets\n",
        "#!python -m pip install graphviz\n",
        "#!python -m pip install pandas\n",
        "#!python -m pip install pudb\n",
        "# !python -m pip install nbconvert"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "# coding=utf-8\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib\n",
        "plt.rcParams['figure.figsize'] = [12, 12]\n",
        "import random\n",
        "import copy\n",
        "#from ipywidgets import GridspecLayout, Button, Layout\n",
        "import math\n",
        "import sys\n",
        "from graphviz import Digraph\n",
        "import pylab\n",
        "\n",
        "import time\n",
        "import networkx as nx\n",
        "from networkx import *\n",
        "import os\n",
        "import pickle"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Bad key text.latex.unicode in file /home/fran/.local/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 112 ('text.latex.unicode : False # use \"ucs\" and \"inputenc\" LaTeX packages for handling')\n",
            "You probably need to get an updated matplotlibrc file from\n",
            "https://github.com/matplotlib/matplotlib/blob/v3.4.2/matplotlibrc.template\n",
            "or from the matplotlib source distribution\n",
            "\n",
            "Bad key savefig.frameon in file /home/fran/.local/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 423 ('savefig.frameon : True')\n",
            "You probably need to get an updated matplotlibrc file from\n",
            "https://github.com/matplotlib/matplotlib/blob/v3.4.2/matplotlibrc.template\n",
            "or from the matplotlib source distribution\n",
            "\n",
            "Bad key pgf.debug in file /home/fran/.local/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 444 ('pgf.debug           : False')\n",
            "You probably need to get an updated matplotlibrc file from\n",
            "https://github.com/matplotlib/matplotlib/blob/v3.4.2/matplotlibrc.template\n",
            "or from the matplotlib source distribution\n",
            "\n",
            "Bad key verbose.level in file /home/fran/.local/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 475 ('verbose.level  : silent      # one of silent, helpful, debug, debug-annoying')\n",
            "You probably need to get an updated matplotlibrc file from\n",
            "https://github.com/matplotlib/matplotlib/blob/v3.4.2/matplotlibrc.template\n",
            "or from the matplotlib source distribution\n",
            "\n",
            "Bad key verbose.fileo in file /home/fran/.local/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 476 ('verbose.fileo  : sys.stdout  # a log filename, sys.stdout or sys.stderr')\n",
            "You probably need to get an updated matplotlibrc file from\n",
            "https://github.com/matplotlib/matplotlib/blob/v3.4.2/matplotlibrc.template\n",
            "or from the matplotlib source distribution\n",
            "In /home/fran/.local/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
            "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
            "In /home/fran/.local/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
            "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
            "In /home/fran/.local/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
            "In /home/fran/.local/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
            "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
            "In /home/fran/.local/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
            "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
            "In /home/fran/.local/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
            "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
            "In /home/fran/.local/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
            "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
            "In /home/fran/.local/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
            "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using matplotlib backend: TkAgg\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "class Slot():\n",
        "\n",
        "    def __init__(self, word, is_core, page_destination):\n",
        "        '''\n",
        "        word : str que l'on souhaite traiter et placer sur la grille\n",
        "        is Core : Booléen un indiquant si le mot traité fait parti du vocabulaire core ou non\n",
        "        page_destination : page liée à ce slot\n",
        "        '''\n",
        "\n",
        "        self.__word = copy.copy(word)\n",
        "        self.__is_core = copy.copy(is_core)\n",
        "        self.__page_destination = copy.copy(page_destination)\n",
        "\n",
        "    # Accesseur\n",
        "    def get_word(self):\n",
        "\n",
        "        return self.__word\n",
        "\n",
        "    # Accesseur\n",
        "    def get_is_core(self):\n",
        "\n",
        "        return self.__is_core\n",
        "\n",
        "    def get_page_destination(self):\n",
        "\n",
        "        return self.__page_destination\n",
        "\n",
        "    def set_word(self, word):\n",
        "\n",
        "        self.__word = word\n",
        "\n",
        "    def set_page_destination(self, page):\n",
        "\n",
        "        self.__page_destination = page\n",
        "\n",
        "    def __str__(self):\n",
        "\n",
        "        dest = self.__page_destination\n",
        "        if dest:\n",
        "            dest = self.__page_destination.get_name()\n",
        "        # return '('+str(self.__word) + ';' + str(self.__is_core) + ';' + str(dest) + ')'\n",
        "        return f'{self.__word}({dest})'\n",
        "\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "hsUuqrUF91aG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "class Page():\n",
        "\n",
        "    #Constructor\n",
        "    def __init__(self, name, row_size, col_size):\n",
        "\n",
        "        self.__name = name\n",
        "        self.__row_size = row_size\n",
        "        self.__col_size = col_size\n",
        "        self.__full = False\n",
        "        self.__slots = []\n",
        "        self.__fill()\n",
        "        self.__last_R = 0\n",
        "        self.__last_C = 0\n",
        "\n",
        "    #Initialise chacun des slots à None\n",
        "    def __fill(self):\n",
        "\n",
        "      self.__slots = []\n",
        "      for i in range(0, self.__row_size) :\n",
        "        self.__slots.append([None])\n",
        "        for j in range(0, self.__col_size) :\n",
        "          self.__slots[i].append(None)\n",
        "\n",
        "    # Ajoute le Slot slot en position num_row, num_col et renvoie l'ancienne valeur\n",
        "    def set_slot(self, slot, num_row, num_col):\n",
        "\n",
        "      if (num_row >= self.__row_size) or (num_col >= self.__col_size):\n",
        "        print(f'row={num_row}, col={num_col}')\n",
        "        print(f'row_size={self.__row_size}, col_size={self.__col_size}')\n",
        "                \n",
        "        raise Exception('Error: slot row or col out of bounds') \n",
        "\n",
        "      old_value = self.__slots[num_row][num_col]\n",
        "      self.__slots[num_row][num_col] = slot\n",
        "\n",
        "      return old_value\n",
        "\n",
        "    def set_name(self, name):\n",
        "      self.__name = name\n",
        "\n",
        "      return name\n",
        "\n",
        "    # Accessors\n",
        "    def get_name(self):\n",
        "\n",
        "      return self.__name\n",
        "\n",
        "    def get_row_size(self):\n",
        "\n",
        "      return self.__row_size\n",
        "\n",
        "    def get_col_size(self):\n",
        "\n",
        "      return self.__col_size\n",
        "\n",
        "    def get_slot(self, num_row, num_col):\n",
        "\n",
        "      return self.__slots[num_row][num_col]\n",
        "\n",
        "    def get_slot_by_name(self, name):\n",
        "\n",
        "      for row in range(0, self.__row_size):\n",
        "        for col in range (0, self.__col_size):\n",
        "          slot = self.__slots[row][col]\n",
        "          if slot:          \n",
        "            if slot.get_word() == name:\n",
        "              return slot\n",
        "          \n",
        "      print(f'*** slot {name} not found in page {self.__name} ***')\n",
        "      return None\n",
        "    \n",
        "    def get_pictograms(self):\n",
        "\n",
        "      current_page_name = self.get_name()\n",
        "      attributes = {}\n",
        "      for row in range(0, self.__row_size):\n",
        "        for col in range (0, self.__col_size):\n",
        "          slot = self.__slots[row][col]\n",
        "          if slot:\n",
        "            word = slot.get_word()\n",
        "            dest = slot.get_page_destination()\n",
        "            if dest:\n",
        "              dest_page_name = dest.get_name()\n",
        "            else:\n",
        "              dest_page_name = None\n",
        "\n",
        "            id = f'{word}@{current_page_name}'\n",
        "            if id in attributes:\n",
        "              id = f'{id}**'\n",
        "\n",
        "            attributes[id] = [word, row, col, current_page_name, dest_page_name]  \n",
        "\n",
        "      return attributes\n",
        "      \n",
        "    # def get_slot_by_destination(self, dest):\n",
        "      \n",
        "    #   for row in range(0, self.__row_size):\n",
        "    #     for col in range (0, self.__col_size):\n",
        "    #       slot = self.__slots[row][col]\n",
        "    #       if slot:          \n",
        "    #         if slot.get_page_destination == dest:\n",
        "    #           return slot\n",
        "          \n",
        "    #   print(f'*** destination {dest} not found in any slot ofpage {self.__name} ***')\n",
        "    #   return None\n",
        "\n",
        "    def get_slot_list(self):\n",
        "\n",
        "      return self.__slots\n",
        "\n",
        "    #Return true if the slot at position (num_row, num_col) is free, false otherwise\n",
        "    def is_free(self, num_row, num_col):\n",
        "\n",
        "      return self.__slots[num_row][num_col] == None\n",
        "\n",
        "    #Return true if table is full, false otherwise\n",
        "    def is_full(self):\n",
        "\n",
        "      if (self.__full):\n",
        "        return True\n",
        "      for row in range(0, self.__row_size):\n",
        "        for col in range (0, self.__col_size):\n",
        "          if self.__slots[row][col] == None:\n",
        "            return False\n",
        "      self.__full = True\n",
        "      return True\n",
        "\n",
        "    def add_word(self, word, core=False, dest=None) :\n",
        "\n",
        "      if(self.__last_C == self.__col_size) : \n",
        "        self.__last_C = 0\n",
        "        self.__last_R += 1\n",
        "      if(self.__last_R == self.__row_size) :\n",
        "        self.__full = True\n",
        "        print(\"Failed to add word <\", word, \">. The table is full.\")\n",
        "        return None\n",
        "\n",
        "      if(self.__slots[self.__last_R][self.__last_C] == None) :\n",
        "\n",
        "        s = Slot(word, core, dest)\n",
        "        self.__slots[self.__last_R][self.__last_C] = s\n",
        "        self.__last_R\n",
        "        self.__last_C += 1\n",
        "        return word\n",
        "      \n",
        "      self.__last_R\n",
        "      self.__last_C += 1\n",
        "      return self.add_word(word, dest=dest)\n",
        "\n",
        "    # Méthode d'affichage (à revoir ? Efficacité chaînes de caractères)\n",
        "    def __str__(self):\n",
        "\n",
        "      s = \"Page: \" + self.__name + \"\\n(\"\n",
        "      for i in range(0, self.__row_size) : \n",
        "        for j in range(0, self.__col_size) :\n",
        "          s+=str(self.__slots[i][j])\n",
        "          s+=\", \"\n",
        "        s+='\\n'\n",
        "      return s+')'\n",
        "\n",
        "    # fonction auxiliaire pour l'affichage\n",
        "    def create_expanded_button(self, description, button_style):\n",
        "\n",
        "      return Button(description=description, button_style=button_style,\n",
        "                  layout=Layout(height='auto', width='auto'))\n",
        "       \n",
        "    # Affichage alternative (couteaux, debug)\n",
        "    def show(self):\n",
        "\n",
        "      grid = GridspecLayout(self.__row_size, self.__col_size, width='50%')\n",
        "\n",
        "      for i in range(self.__row_size):\n",
        "        for j in range(self.__col_size):\n",
        "          # grid[i, j] = self.create_expanded_button('Button {} - {}'.format(i, j), 'success')\n",
        "          if self.__slots[i][j]:\n",
        "            content = str(self.__slots[i][j])\n",
        "          else:\n",
        "            content = ''\n",
        "          grid[i, j] = self.create_expanded_button(content, 'success')            \n",
        "\n",
        "\n",
        "      return grid\n",
        "\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "8jpKq0PruzrI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grid"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "class Grid():\n",
        "\n",
        "  #Constructor\n",
        "  def __init__(self, input_file, row_size, col_size):\n",
        "\n",
        "    self.__row_size = row_size\n",
        "    self.__col_size = col_size\n",
        "    self.__core_voc = {}\n",
        "    self.__pages = {}\n",
        "    self.__pageCounter = 0     \n",
        "    self.__fusion_id = 0\n",
        "    self.__create_grid(input_file)\n",
        "\n",
        "  #ToDo\n",
        "  def add_word(word):\n",
        "\n",
        "    return\n",
        "\n",
        "  def get_root_page(self):\n",
        "\n",
        "    return self.__pages.get('accueil')\n",
        "\n",
        "  # def __get_last_page(self):\n",
        "\n",
        "  #   return self.__pages[-1]\n",
        "  \n",
        "  def get_nb_pages(self):\n",
        "\n",
        "    return self.__pageCounter\n",
        "  \n",
        "  def get_page_names(self):\n",
        "\n",
        "    return self.__pages.keys()\n",
        "\n",
        "  def get_page(self, name):\n",
        "\n",
        "    return self.__pages.get(name) \n",
        "\n",
        "  def get_page_dict(self):\n",
        "\n",
        "    return self.__pages\n",
        "\n",
        "  def get_core_voc(self):\n",
        "\n",
        "    return self.__core_voc\n",
        "\n",
        "  def get_row_size(self):\n",
        "\n",
        "    return self.__row_size\n",
        "\n",
        "  def get_col_size(self):\n",
        "\n",
        "    return self.__col_size\n",
        "\n",
        "  # We assume that the word has not been already added\n",
        "  def add_word(self, word, dest=None):\n",
        "\n",
        "    # if self.__pages[-1].is_full() :\n",
        "\n",
        "    #   self.__add_page2()\n",
        "\n",
        "    # self.__pages[-1].add_word(word, dest=dest)\n",
        "\n",
        "    return\n",
        "  \n",
        "  def add_word_in_root(self, word, dest=None):\n",
        "\n",
        "    accueil_page = self.__pages.get('accueil')\n",
        "    if accueil_page.is_full() :\n",
        "\n",
        "      print('accueil complète, désolé')\n",
        "      return\n",
        "\n",
        "    accueil_page.add_word(word, dest=dest)\n",
        "\n",
        "    return\n",
        "\n",
        "  def add_new_page(self, name):\n",
        "\n",
        "    return self.__add_page(name)\n",
        "\n",
        "  def __add_page(self, name_page):\n",
        "\n",
        "    page = Page(name_page, self.__row_size, self.__col_size)    \n",
        "    self.__pages[name_page] = page\n",
        "    self.__pageCounter += 1 \n",
        "\n",
        "    return page\n",
        "\n",
        "  def update_leaf_picto(self, extra_page):\n",
        "    '''Recherche le premier pictogramme qui n'a pas de page de destination et mettre en place extra_page\n",
        "        comme destination. Renvoie la page contenant le picto trouvé'''\n",
        "\n",
        "    core_voc_dict = self.get_core_voc()\n",
        "\n",
        "    for page in self.get_page_dict().values():\n",
        "      if page.get_name() != extra_page.get_name():\n",
        "        for row in range(1, page.get_row_size()):\n",
        "          for col in range(1, page.get_col_size()):\n",
        "            slot = page.get_slot(row, col)\n",
        "            if slot:\n",
        "              if not slot.get_page_destination():\n",
        "                slot.set_page_destination(extra_page)\n",
        "                \n",
        "                #m-à-j le tableau d'attributes\n",
        "                for key, picto in core_voc_dict.items():\n",
        "                  if picto[0] == slot.get_word() and picto[1] == row and picto[2] == col and picto[3] == page.get_name():\n",
        "                    picto[4] = extra_page.get_name()\n",
        "                                  \n",
        "                # print([(k,p) for k,p in core_voc_dict.items() if p[3] == 'accueil'])\n",
        "                return page\n",
        "\n",
        "\n",
        "  def __create_grid(self, input_file):\n",
        "    ''' Création d'une grille à partir d'un fichier texte ou d'un tableau d'attributes '''\n",
        "\n",
        "    #références pour le calcul de row_size, col_size et destination\n",
        "    row_ref = 0\n",
        "    col_ref = 0\n",
        "    first_page = None\n",
        "    last_id = None\n",
        "\n",
        "    # l'entrée est un dictionaire de pictogrammes\n",
        "    if isinstance(input_file, dict):\n",
        "      # print(\"Grille créée à partir d'un dictionaire de pictogrammes\")\n",
        "      # print()\n",
        "\n",
        "      self.__core_voc = dict(input_file)\n",
        "\n",
        "      # # obtenir row_size et col_size auprès de input_file\n",
        "      \n",
        "      # for picto in self.__core_voc.values():\n",
        "      #   row = int(picto[1])\n",
        "      #   column = int(picto[2])\n",
        "      #   page = picto[3]\n",
        "\n",
        "      #   if not first_page:\n",
        "      #         first_page = page\n",
        "\n",
        "      #   # determiner la taille de la grille\n",
        "      #   if page == first_page:\n",
        "      #     if row > row_ref:\n",
        "      #       row_ref = row\n",
        "      #     if column > col_ref:\n",
        "      #       col_ref = column\n",
        "      #   else:\n",
        "      #     break\n",
        "      \n",
        "      # self.__row_size = row_ref + 1\n",
        "      # self.__col_size = col_ref + 1\n",
        "\n",
        "    # l'entrée est un fichier .csv en format Augcom\n",
        "    elif input_file.endswith('.csv'):\n",
        "      # print(\"Grille créée à partir du fichier \" + input_file)\n",
        "      # print()\n",
        "\n",
        "      # Fichier brut à traiter\n",
        "      with open(input_file, \"r\") as rawFile:\n",
        "\n",
        "        #Traitement du fichier source\n",
        "        for lines in rawFile:\n",
        "          lines = lines.lower()\n",
        "          sentence = lines.strip()\n",
        "          col = sentence.split(\"\\t\")\t\t\n",
        "\n",
        "          # On gére le problème des lignes semi-vides créées par les liens entre les répertoires\n",
        "          if len(col) > 4:\n",
        "            \n",
        "            word = col[0]\n",
        "            row = int(col[1])\n",
        "            column = int(col[2])\n",
        "            page = col[3]\t\t\t\n",
        "            id = col[4]\n",
        "\n",
        "            # enregistrer le mot, les coordonnées, la page actuelle et la destination de chaque pictogramme\n",
        "            self.__core_voc[id] = [word, row, column, page, None]\n",
        "            \n",
        "            # if not first_page:\n",
        "            #   first_page = page\n",
        "\n",
        "            # # determiner la taille de la grille\n",
        "            # if page == first_page:\n",
        "            #   if row > row_ref:\n",
        "            #     row_ref = row\n",
        "            #   if column > col_ref:\n",
        "            #     col_ref = column\n",
        "            \n",
        "            last_id = id\n",
        "\n",
        "          # We recover the links between the directories\n",
        "          elif len(col) > 1:            \n",
        "            pointed_link = col[1]            \t\t\t\n",
        "            self.__core_voc.get(last_id)[4] = pointed_link\n",
        "      \n",
        "      # self.__row_size = row_ref + 1\n",
        "      # self.__col_size = col_ref + 1\n",
        "\n",
        "    else:\n",
        "      raise Exception('Incompatible input. Only dict (pictos attributes) or .csv files (augcom format) are accepted')\n",
        "\n",
        "    self.__add_core_voc()\n",
        "\n",
        "\n",
        "  def __add_core_voc(self):\n",
        "    \n",
        "    for picto in self.__core_voc.values():\n",
        "      word = picto[0]\n",
        "      row = picto[1]\n",
        "      col = picto[2]\n",
        "      page_name = picto[3]\n",
        "      dest_name = picto[4]\n",
        "\n",
        "      if page_name in self.__pages:\n",
        "        page = self.__pages.get(page_name)\n",
        "      else:\t\t  \n",
        "        page = self.__add_page(page_name)\n",
        "          \n",
        "      if dest_name:\n",
        "        if dest_name in self.__pages:\n",
        "          destination = self.__pages.get(dest_name)\n",
        "        else:\t\t\t\n",
        "          destination = self.__add_page(dest_name)          \n",
        "      else:\n",
        "        destination = None\n",
        "\n",
        "      slot = Slot(word, True, destination)    \n",
        "      page.set_slot(slot, row, col)\n",
        "\n",
        "  def to_graph(self):\n",
        "\n",
        "    nodes = set([])\n",
        "    edges = set([])\n",
        "    for key,page in self.__pages.items():\n",
        "      nodes.add(key)\n",
        "      slots = page.get_slot_list()\n",
        "      for items in slots:\n",
        "        for slot in items:\n",
        "          if slot != None:\n",
        "            dest = slot.get_page_destination()\n",
        "            if dest != None:\n",
        "              dest = dest.get_name()\n",
        "              edges.add((key, dest))\n",
        "    \n",
        "    G=nx.DiGraph()\n",
        "    G.add_nodes_from(nodes)\n",
        "    G.add_edges_from(edges)\n",
        "    nx.draw(G,with_labels=True)\n",
        "    # plt.savefig(\"grid_graph.png\") # save as png\n",
        "    plt.show() # display\n",
        "\n",
        "    return G\n",
        "\n",
        "  def cross_pages(self, page1, page2, parent=None):\n",
        "    ''' Croise page1 avec page2 et toutes les sous-pages analogues reliées aux page1 et page2.\n",
        "        'parent' identifie une page qui fait un appel récursive.\n",
        "        Renvoi 3 choses: \n",
        "        - Un tableau contenant les attributes des pictos dans la page résultante.\n",
        "        - La page résultante\n",
        "        - Un tableau contenant les pictos non affectés à la page résultante lors du croissement.\n",
        "\n",
        "        :parent: page de référence pour mettre en place les pictos de retour.\n",
        "    '''\n",
        "\n",
        "    # nous supposons que les deux pages ont la même taille\n",
        "    if page1:\n",
        "      row_size = page1.get_row_size()\n",
        "      col_size = page1.get_col_size()\n",
        "    elif page2:\n",
        "      row_size = page2.get_row_size()\n",
        "      col_size = page2.get_col_size()\n",
        "    \n",
        "    new_page_name_suffix = random.randint(0,1000)\n",
        "\n",
        "    # tableau de tous les attributs des pictogrammes de la page résultante\n",
        "    attributes = {}\n",
        "    # tableau des pictogrammes non affectés lors de la fusion\n",
        "    unallocated_pictos = {}\n",
        "\n",
        "    # cas 1: Aucune page n'existe\n",
        "    if (not page1) and (not page2):\n",
        "      # print('Rien a croiser, fin de la fonction')\n",
        "      \n",
        "      return {}, None, {}\n",
        "    \n",
        "    # cas 2: seul page1 existe\n",
        "    if page1 and (not page2):\n",
        "      result_page = copy.deepcopy(page1)\n",
        "      picto_dict = result_page.get_pictograms()\n",
        "\n",
        "      # chercher et m-à-j le picto de retour.\n",
        "      for picto in picto_dict.values():\n",
        "        if (picto[0] == 'retour_r') and (picto[1] == row_size - 1) and (picto[2] == col_size - 1):\n",
        "          if parent:\n",
        "            picto_dict[f'retour_r@{result_page.get_name()}'][4] = parent.get_name()\n",
        "            # print('Pictogram de retour mise à jour')\n",
        "      attributes.update(picto_dict)\n",
        "      \n",
        "      return attributes, result_page, {}\n",
        "    \n",
        "    # cas 3: seul page2 existe\n",
        "    if page2 and (not page1):        \n",
        "      result_page = copy.deepcopy(page2) \n",
        "      picto_dict = result_page.get_pictograms()\n",
        "\n",
        "      # chercher et m-à-j le picto de retour.\n",
        "      for picto in picto_dict.values():\n",
        "        if (picto[0] == 'retour_r') and (picto[1] == row_size - 1) and (picto[2] == col_size - 1):\n",
        "          if parent:\n",
        "            picto_dict[f'retour_r@{result_page.get_name()}'][4] = parent.get_name()\n",
        "            # print('Pictogram de retour mise à jour')\n",
        "      attributes.update(picto_dict)\n",
        "      \n",
        "      return attributes, result_page, {}\n",
        "\n",
        "    # cas 4: les deux pages existent\n",
        "    if page1 and page2:\n",
        "\n",
        "      # décider le nom du page à retenir\n",
        "      if random.randint(0,1):\n",
        "        new_page_name = page1.get_name()\n",
        "      else:\n",
        "        new_page_name = page2.get_name()\n",
        "\n",
        "      # TO-DO: Vérifier si new_page_name existe déjà dans les pages selectionées. Deux solutions:  \n",
        "      # - ajouter suffixe au nom de la page pour la differencier des pages de base\n",
        "      # new_page_name += f'_{new_page_name_suffix}'\n",
        "      # où\n",
        "      # - Enregistrer les noms crées au fur et à mesure dans une liste, puis modifier légerement le nom si déjà dans la liste\n",
        "      # # ?? \n",
        "\n",
        "      #page résultante\n",
        "      result_page = Page(new_page_name, row_size, col_size)\n",
        "\n",
        "      #sélectionner les pictos qui vont populer la page résultante\n",
        "      for row in range(row_size):\n",
        "        for col in range(col_size):\n",
        "          slot_page1 = copy.deepcopy(page1.get_slot(row, col))\n",
        "          slot_page2 = copy.deepcopy(page2.get_slot(row, col))\n",
        "          random_selector = random.randint(0,1)\n",
        "\n",
        "          if (slot_page1) and (slot_page2):\n",
        "            dest_1 = slot_page1.get_page_destination()\n",
        "            dest_2 = slot_page2.get_page_destination()\n",
        "\n",
        "            if random_selector:\n",
        "              selected_slot = slot_page1\n",
        "              not_selected_slot = slot_page2\n",
        "              page_name = page1.get_name()\n",
        "              page_name_not_selected = page2.get_name()\n",
        "              \n",
        "            else:\n",
        "              selected_slot = slot_page2\n",
        "              not_selected_slot = slot_page1\n",
        "              page_name = page2.get_name()\n",
        "              page_name_not_selected = page1.get_name()\n",
        "\n",
        "            #déterminer (recursivement) la destination du slot selectionné\n",
        "            if (selected_slot.get_word() != 'retour_r'):              \n",
        "              attribs, selected_dest_page, unalloc = self.cross_pages(dest_1, dest_2, result_page)\n",
        "\t\t\t      # picto de retour trouvé\n",
        "            elif (row == row_size - 1) and (col == col_size - 1):\n",
        "              attribs, selected_dest_page, unalloc = {}, parent, {}\n",
        "\n",
        "            #garder les pictos non affectés --------------------------------------\n",
        "            word_not_selected = not_selected_slot.get_word()\n",
        "            if word_not_selected != 'retour_r':\n",
        "              id_not_selected = f'{word_not_selected}@{page_name_not_selected}'\n",
        "\n",
        "              #si deux pictos non affectés ont le même id, modifier légerement l'id de l'un des deux\n",
        "              if id_not_selected in unallocated_pictos:\n",
        "                # '**' à la fin d'une id indique l'existence de 2 pictos differents avec la même mot et même nom de page \n",
        "                id_not_selected = f'{id_not_selected}**'            \n",
        "                        \n",
        "              unallocated_pictos[id_not_selected] = word_not_selected\n",
        "\n",
        "          elif slot_page1:\n",
        "            selected_slot = slot_page1\n",
        "            page_name = page1.get_name()\n",
        "\n",
        "            if selected_slot.get_word() != 'retour_r':\n",
        "              dest_1 = slot_page1.get_page_destination()\n",
        "              attribs, selected_dest_page, unalloc = self.cross_pages(dest_1, None, result_page)            \n",
        "            else:\n",
        "              if parent:\n",
        "                attribs, selected_dest_page, unalloc = {}, parent, {}              \n",
        "\n",
        "          elif slot_page2:\n",
        "            selected_slot = slot_page2\n",
        "            page_name = page2.get_name()\n",
        "\n",
        "            if selected_slot.get_word() != 'retour_r':\n",
        "              dest_2 = slot_page2.get_page_destination()\n",
        "              attribs, selected_dest_page, unalloc = self.cross_pages(dest_2, None, result_page)            \n",
        "            else:\n",
        "              if parent:\n",
        "                attribs, selected_dest_page, unalloc = {}, parent, {}\n",
        "            \n",
        "          # aucun des pictos n'existe\n",
        "          else: \n",
        "            selected_slot = None            \n",
        "\n",
        "          #m-à-j des attributes des pictogrammes de la page résultante\n",
        "          if selected_slot:\n",
        "            selected_slot.set_page_destination(selected_dest_page)\n",
        "            word = selected_slot.get_word()\n",
        "\n",
        "            #ajouter les pictos des pages de destination\n",
        "            attributes.update(attribs)\n",
        "\n",
        "            #m-à-j le dict de pictos non affectés avec ceux des appels récursives\n",
        "            unallocated_pictos.update(unalloc)\n",
        "\n",
        "            id = f'{word}@{page_name}'\n",
        "\n",
        "            if selected_dest_page:                \n",
        "                dest_page_name = selected_dest_page.get_name()\n",
        "            else:\n",
        "              dest_page_name = None\n",
        "            #si deux pictos ont le même id, modifier légerement l'id de l'un d'eux\n",
        "            if id in attributes:\n",
        "              id = f'{word}@{page_name}**'\n",
        "            \n",
        "            attributes[id] = [word, row, col, new_page_name, dest_page_name]\n",
        "\n",
        "          # mettre en place le picto selectionné dans la page résultante \n",
        "          result_page.set_slot(selected_slot, row, col)     \n",
        "    \n",
        "    return attributes, result_page, unallocated_pictos\n",
        "  \n",
        "  def fusion_with(self, grid):\n",
        "    '''Fusione les pages analogues de deux grilles aléatoirement et renvoi la grille résultante. Elle contient\n",
        "      les pictogrammes des deux grilles'''\n",
        "\n",
        "    current_accueil = self.get_root_page() \n",
        "    foreing_accueil = grid.get_root_page() \n",
        "\n",
        "    attributes_dict, result_page, unalloc_dict = self.cross_pages(current_accueil, foreing_accueil)    \n",
        "\n",
        "    row_size = self.get_row_size()\n",
        "    col_size = self.get_col_size()\n",
        "    new_grid = Grid(attributes_dict, row_size, col_size)\n",
        "\n",
        "    # remplir slots vides avec les pictos non affectées\n",
        "    for page in new_grid.get_page_dict().values():\n",
        "      for row in range(1, row_size):\n",
        "        for col in range(1, col_size):\n",
        "          slot = page.get_slot(row, col)\n",
        "          if not slot:\n",
        "            try:\n",
        "              # renvoyer l'id du pictgramme non affecté suivant\n",
        "              id_next_unalloc_picto = next(iter(unalloc_dict))\n",
        "\n",
        "              #vérifier si l'id du picto non alloué existe déjà dans le tableau d'attributes de la grille \n",
        "              if id_next_unalloc_picto in new_grid.get_core_voc():\n",
        "                new_id = f'{id_next_unalloc_picto}**'\n",
        "                unalloc_dict[new_id] = unalloc_dict.pop(id_next_unalloc_picto)\n",
        "                id_next_unalloc_picto = new_id\n",
        "\n",
        "              unalloc_picto = unalloc_dict.pop(id_next_unalloc_picto)\n",
        "              word = unalloc_picto\n",
        "              slot = Slot(word, False, None)\n",
        "              page.set_slot(slot, row, col)\n",
        "              \n",
        "              #m-à-j du dict d'attriburtes de la nouvelle grille\n",
        "              new_grid.get_core_voc()[id_next_unalloc_picto] = [word, row, col, page.get_name(), None]     \n",
        "\n",
        "            # unalloc_dict est vide         \n",
        "            except:\n",
        "              print('** fusion complète 1 **')\n",
        "              return new_grid\n",
        "    \n",
        "    # gérer le cas où il y a plus de pictos non alloués que de slots vides.\n",
        "    while len(unalloc_dict):\n",
        "            \n",
        "      # créer et ajouter une page extra pour les allouer\n",
        "      extra_page_name = f'extra_{random.randint(0,1000)}'    \n",
        "      extra_page = new_grid.add_new_page(extra_page_name)\n",
        "\n",
        "      # choisir le picto connecté à la page extra. On parcours les pages en partant de l'accueil.\n",
        "      origin_page = new_grid.update_leaf_picto(extra_page)    \n",
        "\n",
        "      # mettre en place le picto de retour\n",
        "      if origin_page:\n",
        "        picto_retour = Slot('retour_r', False, origin_page)\n",
        "        extra_page.set_slot(picto_retour, row_size - 1, col_size - 1)\n",
        "        new_grid.get_core_voc()[f'retour_r@{extra_page_name}'] = ['retour_r', row_size - 1, col_size - 1, extra_page_name, origin_page.get_name()]\n",
        "      \n",
        "      # remplir slots vides de la PAGE EXTRA avec des pictos non affectées\n",
        "      for row in range(1, row_size):\n",
        "          for col in range(1, col_size):\n",
        "            slot = extra_page.get_slot(row, col)\n",
        "            # si le slot est vide\n",
        "            if not slot:\n",
        "              try:\n",
        "                # renvoyer l'id du pictgramme non affecté suivant\n",
        "                id_next_unalloc_picto = next(iter(unalloc_dict))\n",
        "\n",
        "                #vérifier si l'id du picto non alloué existe dans le dict d'attributes de la grille \n",
        "                if id_next_unalloc_picto in new_grid.get_core_voc():\n",
        "                  new_id = f'{id_next_unalloc_picto}**'\n",
        "                  unalloc_dict[new_id] = unalloc_dict.pop(id_next_unalloc_picto)\n",
        "                  id_next_unalloc_picto = new_id\n",
        "\n",
        "                unalloc_picto = unalloc_dict.pop(id_next_unalloc_picto)\n",
        "                word = unalloc_picto\n",
        "                slot = Slot(word, False, None)\n",
        "                extra_page.set_slot(slot, row, col)\n",
        "\n",
        "                #m-à-j du dict d'attriburtes de la nouvelle grille\n",
        "                new_grid.get_core_voc()[id_next_unalloc_picto] = [word, row, col, extra_page.get_name(), None]              \n",
        "              except:\n",
        "                print('** fusion complète 2 **')                \n",
        "                return new_grid\n",
        "                \n",
        "    return new_grid\n",
        "\n",
        "  def shuffle(self):\n",
        "    '''Mélange les pictogrammes à l'intérieure de chaque page de la grille'''\n",
        "\n",
        "    core_voc_copy = copy.deepcopy(self.get_core_voc())\n",
        "\n",
        "    print('VOC_AVANT: ')\n",
        "    print(core_voc_copy)\n",
        "\n",
        "    # new_grid_core_voc = new_grid.get_core_voc()\n",
        "    row_size = self.get_row_size()\n",
        "    col_size = self.get_col_size()\n",
        "\n",
        "    #créer liste de coordoneées de slots\n",
        "    all_coords = [(i,j) for i in range(1, row_size) for j in range(1, col_size)]\n",
        "    \n",
        "    #omettre le picto dans le coin en bas à droite (retour, plus, etc) \n",
        "    all_coords.pop()\n",
        "\n",
        "    for page_name in self.get_page_dict():\n",
        "      coords_list = list(all_coords)      \n",
        "      #mélange la liste\n",
        "      random.shuffle(coords_list)\n",
        "      info = []\n",
        "      c=0\n",
        "\n",
        "      for id, picto in self.get_core_voc().items():\n",
        "        \n",
        "        # choisir pictos dans la même page. Ne tenir pas compte des pictos en ligne/col = 0. \n",
        "        if (picto[3] == page_name) and (picto[1] != 0) and (picto[2] != 0):\n",
        "          info.append((id, picto))\n",
        "          if (picto[1] != row_size-1) or (picto[2] != col_size-1):     \n",
        "            \n",
        "            try:          \n",
        "              row, col = coords_list.pop()\n",
        "            except:\n",
        "              \n",
        "              self.display('pb_grid')\n",
        "              raise Exception('PROBLEM')\n",
        "            # slot = Slot(picto[0], False, self.get_page(picto[4]))\n",
        "            # new_grid.get_page(page_name).set_slot(slot, row, col)\n",
        "\n",
        "            #affecter les nouvelles coordonnées aux pictos de la pag courante\n",
        "            core_voc_copy[id][1] = row\n",
        "            core_voc_copy[id][2] = col\n",
        "\n",
        "    # check_voc(core_voc_copy)\n",
        "\n",
        "    print('VOC_APRES: ')\n",
        "    print(core_voc_copy)\n",
        "    print()\n",
        "    \n",
        "    return Grid(core_voc_copy, row_size, col_size)\n",
        "\n",
        "  def to_text(self, output_name='grid_text.csv'):\n",
        "    '''Crée un fichier texte (.csv) décrivant la grille en format augcom'''\n",
        "\n",
        "    print(\"output file is \" + output_name)\n",
        "    print()\n",
        "    sorted_attrib_dict = {}\n",
        "\n",
        "    # trier le dict d'attributes par nom de page\n",
        "    for page_name in self.get_page_dict():     \n",
        "      for picto_id, attributes in self.get_core_voc().items():\n",
        "        if attributes[3] == page_name:\n",
        "          sorted_attrib_dict[picto_id] = self.get_core_voc().get(picto_id)       \n",
        "\n",
        "    # Fichier résultant\n",
        "    with open(output_name, \"w\") as text_file:\n",
        "      for picto_id, attributes in sorted_attrib_dict.items():\n",
        "        print(f'{attributes[0].upper()}\\t{attributes[1]}\\t{attributes[2]}\\t{attributes[3]}\\t{picto_id}', file=text_file) \n",
        "        if attributes[4]:\n",
        "          print(f'\\t\\t\\t{picto_id}\\t{attributes[4]}', file=text_file)\n",
        "\n",
        "  # Méthode d'affichage 1\n",
        "  def __str__(self):\n",
        "\n",
        "    s = 'grid : {\\n'\n",
        "    for page in self.__pages.values():\n",
        "      s+= str(page) + '\\n'\n",
        "    s += '}\\n'\n",
        "    return s\n",
        "\n",
        "  # Méthode d'affichage 2\n",
        "  def display(self, name='default'):\n",
        "    ''' Génére un image detaillé de l'estructure de la grille. Il utilise Graphviz et le language DOT'''\n",
        "\n",
        "    graph = Digraph(comment='Test', node_attr={'shape': 'record'}) #, 'fixedsize': 'true', 'width':'4', 'height':'2'})\n",
        "    row_size = self.get_row_size()\n",
        "    col_size = self.get_col_size()\n",
        "    slot_index = 0\n",
        "\n",
        "    for page_name,page in self.get_page_dict().items():\n",
        "      \n",
        "      attribute_string = '{ '\n",
        "      separator_1 = ''\n",
        "      for row in range(0, row_size):\n",
        "        separator_2 = ''\n",
        "        attribute_string += f'{separator_1}' + ' { '\n",
        "        for col in range(0, col_size):\n",
        "          slot_index  = row * col_size + col\n",
        "          slot = page.get_slot(row, col)\n",
        "\n",
        "          if slot:\n",
        "            word = slot.get_word()\n",
        "            dest = slot.get_page_destination()\n",
        "            #ajouter lien entre picto directoire et la page correspondante \n",
        "            if dest:              \n",
        "              graph.edge(f'{page_name}:{slot_index}', f'{dest.get_name()}')\n",
        "          elif row == 0 and col == 0:\n",
        "            word = page_name.upper()\n",
        "          else:\n",
        "            word = ''\n",
        "\n",
        "          attribute_string += f'{separator_2}<{slot_index}>{word} '\n",
        "          separator_2 = '|'\n",
        "\n",
        "        separator_1 = '|'\n",
        "        attribute_string += '} '\n",
        "      attribute_string += ' }'\n",
        "\n",
        "      #créer noeud \n",
        "      graph.node(f'{page_name}', f'{attribute_string}')\n",
        "      #print(graph.source)\n",
        "      graph.render(filename=name,format='png')\n",
        "\n",
        "      \n",
        "    return graph"
      ],
      "outputs": [],
      "metadata": {
        "id": "zdA2LhKvjRQx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "def compute_distances(grid, movement_factor=1, selection_factor=1):\n",
        "  '''\n",
        "  Calcule la distance entre chaque paire de pictogrammes à l'intérieure de chaque page d'une grille\n",
        "  Prend en compte la difficulté du mouvement (movement_factor) et la difficulté de la sélection (selection_factor)\n",
        "  '''\n",
        "\n",
        "  # Dictionaire des distances\n",
        "  disTab = grid.get_core_voc()\n",
        "  # Copie du dict à utiliser dans la boucle interne\n",
        "  distTab_copy = copy.deepcopy(disTab) \n",
        "  # Final distances\n",
        "  distances = ''\n",
        "\n",
        "  # Définition du poids du mouvement\n",
        "  m = movement_factor\n",
        "  # Définition du poids du temps de sélection\n",
        "  n = selection_factor\n",
        "\n",
        "  for key1,picto1 in disTab.items():\n",
        "    # ID de référence\n",
        "    refID = key1\n",
        "    # On crée une variable qui prend comme valeur le nom de la page actuelle\n",
        "    currentPage = picto1[3]\n",
        "    # On récupere les coordonnées\n",
        "    x1 = picto1[1]\n",
        "    y1 = picto1[2]\n",
        "    # On enleve picto1 du deuxième dict\n",
        "    distTab_copy.pop(key1)\n",
        "    \n",
        "    for key2,picto2 in distTab_copy.items():\n",
        "      # ID de deuxième picto en question\n",
        "      ID = key2\n",
        "\n",
        "      # On vérifie que l'on est toujours sur la bonne page\n",
        "      currentPage2 = picto2[3]\n",
        "      x2 = picto2[1]\n",
        "      y2 = picto2[2]\n",
        "\n",
        "      if currentPage2 == currentPage:\n",
        "        # Si les deux IDs sont différents on récupère les coordonnées x et y de chacun\n",
        "        if refID != ID:\n",
        "          # Calcul des distances Euclidiennes\n",
        "          squaredDistance = (x1 - x2) ** 2 + (y1 - y2) ** 2\n",
        "          pictoDistance = math.sqrt(squaredDistance)\n",
        "\n",
        "          #Si le mot de d'arrivée de l'arc est un répertoire: C=(P1,P2)m\n",
        "          if \"_r@\" in ID :\n",
        "            #On écrit la fomule sans le n\n",
        "            distances += \"Mot à Répertoire\" + \"\\t\" + refID + \"\\t\" + ID + \"\\t\" + str(pictoDistance * m) + \"\\n\"\n",
        "\n",
        "          #Si le pictogarmme départ et celui d'arrivée sont des mots: C=(P1,P2)m+n            \n",
        "          else :\n",
        "            distances += \"Mot à Mot\" + \"\\t\" + refID + \"\\t\" + ID + \"\\t\" + str(pictoDistance * m + n) + \"\\n\"\n",
        "            distances += \"Mot à Mot\" + \"\\t\" + ID + \"\\t\" + refID + \"\\t\" + str(pictoDistance * m + n) + \"\\n\"\n",
        "\n",
        "    # On écrit le lien entre un pictogramme directeur (plus, retour, pagination, flèche retour et répertoires) et la page\n",
        "    if picto1[4]:\n",
        "      # Formule correspondnat uniquement à l'action de sélection: C=n\n",
        "      distances += \"Picto directeur à Page\" + \"\\t\" + refID + \"\\t\" + picto1[4] + \"\\t\" + str(n) + \"\\n\"\n",
        "\n",
        "    # On écrit le lien entre la page et le pictogramme \n",
        "    # On calcule la distance entre le lien de la page et des pictogrammes à partir du pictogramme en haut à gauche avec x=1 et y=1\n",
        "    squaredDistance3 = (1 - x1) ** 2 + (1 - y1) ** 2\n",
        "    pageToPicto = math.sqrt(squaredDistance3)\n",
        "\n",
        "    #Si le pictogramme d'arrivée de l'arc est un répetoire: C=(P(1,1)P2)m\n",
        "    if \"_r@\" in picto1[0] :\n",
        "      #On calcule sans le n\n",
        "      distances += \"Page à Répertoire\" + \"\\t\" + currentPage + \"\\t\" + picto1[0] + \"\\t\" + str(pageToPicto* m) + \"\\n\"\n",
        "    # Si le pictogramme d'arrivée est un mot: C=(P(1,1)P2)m+n\n",
        "    else :\n",
        "      distances += \"Page à Mot\" + \"\\t\" + currentPage + \"\\t\" + refID + \"\\t\" + str(pageToPicto * m + n) + \"\\n\"\n",
        "\n",
        "  # with open('dist_file.csv', \"w\") as dist:\n",
        "  #   for line in distances.splitlines():\n",
        "  #     dist.write(f'{line}\\n')\n",
        "\n",
        "  return distances"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cost"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "# FONCTIONS AUXILIAIRES POUR LE CALCUL DU COÛT DE PRODUCTION\n",
        "#--------------------------------------------------------------\n",
        "\n",
        "class WeightedPath:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.path = []\n",
        "        self.weight = 0\n",
        "\n",
        "\n",
        "# Fonction qui établit le noeud à partir duquel il faut commencer à calculer un arc\n",
        "'''\n",
        "text = texte d'entrée\n",
        "nodeList = liste de tous les noeuds du graphe\n",
        "edgeList = tableau associatif de tous les arcs avec en clé le noeud tête et en valeurs le noeud pointé et le poids de l'arc\n",
        "G = graphe initial (DiGraph)\n",
        "'''\n",
        "\n",
        "def initialNode(text, nodeList, edgeList, G):\n",
        "    path = []\n",
        "    stock = []\n",
        "    totalWeight = 0\n",
        "    startNode = \"accueil\"\n",
        "\n",
        "    # On parcours le fichier texte\n",
        "    for line in text.splitlines():\n",
        "        line = line.lower()\n",
        "        line = line.strip()\n",
        "        # On évite les lignes vides\n",
        "        if line != \"\":\n",
        "            # On récupère le plus court chemin\n",
        "            words = shortestPath(startNode, line, nodeList, edgeList, G)\n",
        "\n",
        "            if words == -1:\n",
        "              return list([-1])\n",
        "\n",
        "            path = words.path\n",
        "            # On récupère le dernier élément de la liste\n",
        "            startNode = path[-1]\n",
        "            # On ajoute le poids\n",
        "            totalWeight += words.weight\n",
        "\n",
        "        finalPath = []\n",
        "        # On ajoute le premier élément de la liste au chemin final\n",
        "        finalPath.append(path[0])\n",
        "        # On parcours le chemin\n",
        "        for i in range(1, len(path)):\n",
        "            # Si on toruve deux mots qui se suivent différents\n",
        "            if path[i - 1] != path[i]:\n",
        "                # on ajoute l'elt au chemin final\n",
        "                finalPath.append(path[i])\n",
        "        # On stocke dans une liste le chemin et le poids total\n",
        "        # stock.append(str(finalPath) + \" \" + str(totalWeight))\n",
        "        stock.append((finalPath, totalWeight))\n",
        "\n",
        "    return stock\n",
        "\n",
        "\n",
        "# Fonction qui prend en entrée un mot de la phrase et en fait une liste de noeuds possibles\n",
        "'''\n",
        "nodeList = liste de tous les noeuds du graphe\n",
        "word = chaque word de la phrase d'entrée \n",
        "'''\n",
        "\n",
        "def textToNodes(word, nodeList):\n",
        "    candidatesNode = []\n",
        "    # on parcours la liste des noeuds\n",
        "    for i in range(0, len(nodeList)):\n",
        "        # on découpe au '@' pour récupérer le mot d'origine au lieu de l'identifiant complet\n",
        "        wordNode = nodeList[i].split(\"@\")\n",
        "        # Si le mot d'origine est égal au word de la phrase\n",
        "        if wordNode[0] == word:\n",
        "            # on l'ajoute à la liste des noeuds canidats potentiels\n",
        "            candidatesNode.append(nodeList[i])\n",
        "    return candidatesNode\n",
        "\n",
        "\n",
        "# Fonction de calcul du plus court path\n",
        "'''\n",
        "initialNode = point de départ de la recherche dans le graphe\n",
        "sentance = phrase d'entrée pour laquelle il faut calculer le cout de production\n",
        "nodeList = liste de tous les noeuds du graphe\n",
        "edgeList = tableau associatif de tous les arcs avec en clé le noeud tête et en valeurs le noeud pointé et le weight de l'arc\n",
        "'''\n",
        "\n",
        "def shortestPath(initialNode, sentance, nodeList, edgeList, G):\n",
        "    initialNodes = []\n",
        "    words = sentance.split(\" \")\n",
        "    shortestPath = []\n",
        "    # Initialisation du poids total\n",
        "    totalWeight = 0\n",
        "    initialNodes.append(initialNode)\n",
        "    \n",
        "    # On créé la variable du chemin final\n",
        "    finalPath = []\n",
        "    pathList = []\n",
        "\n",
        "    # On créé un nouveau graphe avec la liste des candidats\n",
        "    coupleGraphe = nx.DiGraph()\n",
        "    # coupleGraphe.add_node(\"end\")\n",
        "\n",
        "    index = 0\n",
        "    # On parcours la phrase\n",
        "    for word in words:\n",
        "        minWeight = 10000\n",
        "        # On stocke dans une variable les mots \"candidats\" pour créer le plus court chemin        \n",
        "        candidates = textToNodes(word, nodeList)\n",
        "\n",
        "        # Pour chaque candidat\n",
        "        for candidate in candidates:\n",
        "            # On ajoute les candidats comme noeuds du sous graphe\n",
        "            coupleGraphe.add_node(candidate)\n",
        "\n",
        "            # Quand on arrive à l fin d ela phrase\n",
        "            if index == len(words) - 1:\n",
        "                # On créé un arc \"end\" de poids 0\n",
        "                coupleGraphe.add_edge(candidate, \"end\", weight=0)\n",
        "            elif index == 0:\n",
        "                # On créé un arc \"accueil\" de poids 0\n",
        "                coupleGraphe.add_edge(\"accueil\", candidate, weight=0)\n",
        "\n",
        "            # On parcours la liste des noeuds initiaux\n",
        "            for firstNode in initialNodes:\n",
        "                # On extrait le plus court chemin entre le premier noeud et le candidat avec la fonctionn \"shortest_path \"fonction Networkx\n",
        "                try:\n",
        "                    path = nx.shortest_path(G, source=firstNode, target=candidate)\n",
        "                except nx.NetworkXNoPath:\n",
        "                    \n",
        "                    PB = True\n",
        "                    print (\"No path between %s and %s.\" % (firstNode, candidate))\n",
        "\n",
        "                    return -1\n",
        "\n",
        "                    # plt.clf()\n",
        "                    # pos = nx.spring_layout(G, k=0.85, iterations=20)                    \n",
        "                    # nx.draw(G, pos, edge_color='magenta', width = 0.5, node_size=60, with_labels=True)\n",
        "                    # time.sleep(60)\n",
        "\n",
        "\n",
        "                # On initialise le poids\n",
        "                weight = 0\n",
        "                # On parcours le chemin\n",
        "                for i in range(1, len(path)):\n",
        "                    edgePrevNode = edgeList[path[i - 1]]\n",
        "                    for edge in edgePrevNode:\n",
        "                        # On vérifie que le premier elt de la variable arc = shortest path de i\n",
        "                        if edge[0] == path[i]:\n",
        "                            weight += edge[1]                                                        \n",
        "\n",
        "                # Si le poids est inférieur au poids minimum\n",
        "                if weight < minWeight:\n",
        "                    # Le poids min prend la valeur du poids\n",
        "                    minWeight = weight\n",
        "\n",
        "                pathList.append(path)\n",
        "\n",
        "                coupleGraphe.add_edge(path[0], path[-1], weight=weight)\n",
        "                \n",
        "        # On modifie le point de départ de la fonction\n",
        "        initialNodes = candidates\n",
        "        index = index + 1\n",
        "\n",
        "        # On calcule la somme des poids entre les arcs\n",
        "        totalWeight += minWeight   \n",
        "    \n",
        "    # On applique à nouveau une recherche du plus court chemin dans le sous graphe\n",
        "    try:        \n",
        "        shortestpath = nx.shortest_path(coupleGraphe, source=\"accueil\", target=\"end\")\n",
        "    except nx.NetworkXNoPath:\n",
        "\n",
        "        print (\"No path between %s and %s. Please check the input phrase\" % (\"accueil\", \"end\"))\n",
        "        sys.exit()\n",
        "        \n",
        "    # On céé le chemin final\n",
        "    wordIndex = 0\n",
        "    # On parcours la liste des chemins\n",
        "    for path in pathList:\n",
        "        if (shortestpath[wordIndex] == path[0]) and (shortestpath[wordIndex + 1] == path[-1]):\n",
        "            for words in path:\n",
        "                finalPath.append(words)\n",
        "            wordIndex = wordIndex + 1\n",
        "    \n",
        "    # On créé un objet\n",
        "    weightedPath = WeightedPath()\n",
        "    weightedPath.path = finalPath\n",
        "    weightedPath.weight = totalWeight\n",
        "\n",
        "    return weightedPath\n",
        "\n",
        "# Fonction qui stocke un objet dans un fichier .pkl\n",
        "'''\n",
        "obj = lobjet à stocker\n",
        "name = nom du fichier créé\n",
        "'''\n",
        "\n",
        "def save_obj(obj, name ):\n",
        "    with open(name + '.pkl', 'wb') as f:\n",
        "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# Fonction qui récupere un objet contenu dans un fichier .pkl\n",
        "'''\n",
        "name = nom du fichier cible\n",
        "'''\n",
        "\n",
        "def load_obj(name ):\n",
        "    with open(name + '.pkl', 'rb') as f:\n",
        "        return pickle.load(f)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "def compute_cost(input_sentence, distances):\n",
        "  # start_time = time.time()\n",
        "\n",
        "  # variable qui garde le meilleur chemin et le coût final\n",
        "  result = []\n",
        "      \n",
        "  # # On créé le graph G\n",
        "  graph = nx.DiGraph()\n",
        "\n",
        "  # tableau associatif (dict) qui comprendra les noeuds et les poids\n",
        "  edgeList = {}\n",
        "\n",
        "  # # On parcours les distances pour déterminer les noeuds, les arcs et les poids\n",
        "  for line in distances.splitlines():\n",
        "      line = line.strip()\n",
        "      col = line.split('\\t')\n",
        "      \n",
        "      # Addition du noeud au graphe\n",
        "      graph.add_node(col[1])\n",
        "\n",
        "      # Création des arcs avec leurs poids\n",
        "      graph.add_edge(col[1], col[2], weight=col[3])\n",
        "\n",
        "      # Création du tableau associatif \n",
        "      if col[1] in edgeList.keys():\n",
        "          edgeList[col[1]].append((col[2], float(col[3])))\n",
        "      else:\n",
        "          edgeList[col[1]] = [(col[2], float(col[3]))]\n",
        "\n",
        "  # création de la liste des noeuds\n",
        "  nodeList = list(graph.nodes())\n",
        "\n",
        "  output = initialNode(input_sentence, nodeList, edgeList, graph)\n",
        "\n",
        "  # Sauvegarde des résultats\n",
        "  for elt in output:\n",
        "      result.append(elt)      \n",
        "\n",
        "  # print(\"--- %s seconds ---\" % '{:5.5}'.format(time.time() - start_time))\n",
        "\n",
        "  return result"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        " import pandas as pd\n",
        " \n",
        " def check_missing(d): \n",
        "  exist=False\n",
        "  for n in d.get_core_voc():\n",
        "    if 'voyager' in n:\n",
        "      exist = True\n",
        "  if not exist:\n",
        "    df = pd.DataFrame(d.get_core_voc().values(), columns=['word', 'row', 'col', 'page', 'dest']).sort_values('page')\n",
        "    print(df)\n",
        "    d.display()\n",
        "    print('check_missing_signal..........!')\n",
        "    # sys.exit(1)\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ALGORITHME GÉNÉTIQUE"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "from deap import base\n",
        "from deap import creator\n",
        "from deap import tools\n",
        "\n",
        "PB = False\n",
        "\n",
        "# CX_PROB  est la probabilité avec laquelle deux individus se croisent\n",
        "# MUT_PROB est la probabilité de mutation d'un individu\n",
        "CX_PROB, MUT_PROB = 0.9, 0.9    ## todo: choisir les probs\n",
        "\n",
        "# SCORE_THRESHOLD est le coût ciblé.\n",
        "# MAX_ITER est le nombre maximale d'itérations\n",
        "SCORE_THRESHOLD, MAX_ITER = 7.0, 5\n",
        "\n",
        "# Dimensions des grilles\n",
        "ROW_SIZE = 4\n",
        "COL_SIZE = 4\n",
        "\n",
        "# phrase d'entrée\n",
        "sentence = 'je voyager train'\n",
        "\n",
        "def init_grid(container, source_file):\n",
        "  \n",
        "  return container(source_file, ROW_SIZE, ROW_SIZE)\n",
        "\n",
        "def init_population(container, func, source_file_list):\n",
        "  \n",
        "  return container(func(file) for file in source_file_list)\n",
        "\n",
        "#Créer le container pour la fonction de coût et les individus\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))      ##todo: arrange weights quand plusieurs fitnesses (sentences) \n",
        "creator.create(\"Individual\", Grid, fitness=creator.FitnessMax)\n",
        "\n",
        "# Initialisateurs\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register(\"individual\", init_grid, creator.Individual)\n",
        "toolbox.register(\"population\", init_population, list, toolbox.individual)\n",
        "\n",
        "# Fonction d'évaluation du coût de production\n",
        "def evalProdCost(sentence, individual):\n",
        "  distances = compute_distances(individual)\n",
        "  cost = compute_cost(sentence, distances)\n",
        "  \n",
        "  if len(cost) == 1:\n",
        "    if cost[0] == -1:\n",
        "      print([(k,p) for k,p in individual.get_core_voc().items() if p[3] == 'accueil'])\n",
        "      return individual.display()\n",
        "\n",
        "  # if PB:\n",
        "  #   print(individual.get_page_names())\n",
        "  #   individual.display()\n",
        "  #   sys.exit(1)\n",
        "          \n",
        "  return cost[0][1],    ##todo: plusieurs sentences\n",
        "\n",
        "# Fonction de fusion externe(fusion)\n",
        "def external_fusion(individual1, individual2):\n",
        "  new_grid = individual1.fusion_with(individual2)  \n",
        "\n",
        "  return toolbox.individual(new_grid.get_core_voc())\n",
        "\n",
        "# Fonction de fusion interne (shuffle)\n",
        "def internal_fusion(individual):\n",
        "  new_grid = individual.shuffle()\n",
        "\n",
        "  return toolbox.individual(new_grid.get_core_voc())\n",
        "\n",
        "# Operateurs génétiques\n",
        "toolbox.register(\"evaluate\", evalProdCost, sentence)\n",
        "toolbox.register(\"mate\", external_fusion)\n",
        "toolbox.register(\"mutate\", internal_fusion)\n",
        "toolbox.register(\"select\", tools.selBest)\n",
        "\n",
        "# tools.mutFlipBit()\n",
        "# tools.cxTwoPoint()\n",
        "# tools.selTournament()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "#PIPEPLINE\n",
        "\n",
        "def main(files):\n",
        "  #Création de la population\n",
        "  pop = toolbox.population(files)\n",
        "\n",
        "  # Évaluer l'ensemble de la population\n",
        "  fitnesses = list(map(toolbox.evaluate, pop))\n",
        "  for ind, fit in zip(pop, fitnesses):\n",
        "    ind.fitness.values = fit\n",
        "\n",
        "  # Effectuer l'évolution\n",
        "\n",
        "  # Extraction de toutes les fitnesses\n",
        "  fits = [ind.fitness.values[0] for ind in pop]\n",
        "\n",
        "  # Variable permettant de suivre le nombre de générations\n",
        "  g = 0\n",
        "\n",
        "  # Commencez l'évolution ***\n",
        "\n",
        "  # évoluer jusqu'à ce qu'un individu atteigne SCORE_THRESHOLD ou que le nombre de générations atteigne MAX_ITER\n",
        "  while max(fits) > SCORE_THRESHOLD and g < MAX_ITER:\n",
        "    # A new generation\n",
        "    g = g + 1\n",
        "    print(\"-- Generation %i --\" % g)\n",
        "\n",
        "    # Sélectionnez les individus de la génération suivante\n",
        "    offspring = toolbox.select(pop, len(pop))\n",
        "\n",
        "    # Cloner les individus sélectionnés\n",
        "    #offspring = list(map(toolbox.clone, offspring))\n",
        "\n",
        "    # Appliquer le crossover et la mutation sur la progéniture ***\n",
        "\n",
        "    new_cx_individuals = []\n",
        "    for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
        "      if random.random() < CX_PROB:\n",
        "        n_ind = toolbox.mate(child1, child2)\n",
        "\n",
        "        new_cx_individuals.append(n_ind)\n",
        "\n",
        "        # check_missing(n_ind)\n",
        "        \n",
        "        # del child1.fitness.values\n",
        "        # del child2.fitness.values\n",
        "\n",
        "    # m-à-j offspring    \n",
        "    offspring.extend(new_cx_individuals)\n",
        "\n",
        "    # new_mut_individuals = []\n",
        "    # for mutant in offspring:\n",
        "    #   if random.random() < MUT_PROB:\n",
        "    #     n_ind = toolbox.mutate(mutant)\n",
        "    #     new_mut_individuals.append(n_ind)\n",
        "\n",
        "    #     # check_voc(n_ind.get_core_voc())\n",
        "    #     # del mutant.fitness.values\n",
        "\n",
        "    # # m-à-j offspring \n",
        "    # offspring.extend(new_mut_individuals)\n",
        "\n",
        "    # Evaluer les individus avec une fitness invalide ***\n",
        "    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
        "    fitnesses = map(toolbox.evaluate, invalid_ind)\n",
        "    for ind, fit in zip(invalid_ind, fitnesses):\n",
        "      ind.fitness.values = fit\n",
        "\n",
        "    # print(*[i.fitness.values for i in offspring])\n",
        "\n",
        "    # remplacer l'ancienne population par la descendance\n",
        "    pop = offspring\n",
        "\n",
        "  # Rassemblez tous les fitness dans une liste et imprimez les statistiques\n",
        "  fits = [ind.fitness.values[0] for ind in pop]\n",
        "            \n",
        "  length = len(pop)\n",
        "  mean = sum(fits) / length\n",
        "  sum2 = sum(x*x for x in fits)\n",
        "  std = abs(sum2 / length - mean**2)**0.5\n",
        "\n",
        "  print(\"  Min %s\" % min(fits))\n",
        "  print(\"  Max %s\" % max(fits))\n",
        "  print(\"  Avg %s\" % mean)\n",
        "  print(\"  Std %s\" % std)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 100)\n",
        "\n",
        "def check_voc(dict_att,grid):\n",
        "\n",
        "  df = pd.DataFrame(dict_att.values(), columns=['word', 'row', 'col', 'page', 'dest'])\n",
        "  df2 = df.groupby(['row', 'col', 'page']).size()\n",
        "  if sum(df2.values) != len(df2.values):\n",
        "    print(pd.DataFrame.from_dict(grid.get_core_voc(), orient='index').sort_values([3]))\n",
        "    raise Exception('COORDONÉES REPÉTÉES')\n",
        "  \n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "source": [
        "gg=Grid('testing/grid_2_3p_raw.csv', 4,4)\n",
        "check_voc(gg.get_core_voc(), gg)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK.....!\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TESTING"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "## TEST PIPELINE\n",
        "\n",
        "path1 = 'testing/'\n",
        "path2 = '/home/fran/mosig/internship/sarah/'\n",
        "\n",
        "# noms de fichiers texte (corpus) d\n",
        "# e chaque grille \n",
        "files = [f'{path1}grid_1_3p_raw.csv', f'{path1}grid_2_2p_raw.csv']\n",
        "# files = [f'{path1}grid_1_3p_raw.csv', f'{path2}Corrected_proloquo_FR_brut.csv']\n",
        "\n",
        "main(files)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "g1=Grid('testing/grid_1_3p_raw.csv', 4,4)\n",
        "g2=Grid('testing/grid_2_3p_raw.csv', 4,4)\n",
        "\n",
        "# p=g1.get_root_page().get_pictograms()\n",
        "# for k,p in p.items():\n",
        "#   print(f'{k}:{p}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "je@accueil:['je', 1, 1, 'accueil', None]\n",
            "train@accueil:['train', 1, 2, 'accueil', None]\n",
            "avion@accueil:['avion', 2, 1, 'accueil', None]\n",
            "animaux_r@accueil:['animaux_r', 2, 2, 'accueil', 'animaux']\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "********************************************************************************************************"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "#!python -m pip install networkx\n",
        "#!python -m pip install matplotlib==2.2.3\n",
        "#!python -m pip install ipywidgets\n",
        "#!python -m pip install graphviz\n",
        "#!python -m pip install pandas\n",
        "#!python -m pip install pudb\n",
        "# !python -m pip install nbconvert\n",
        "# !python -m pip install nbconvert -U\n",
        "# coding=utf-8\n",
        "\n",
        "\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "# %matplotlib\n",
        "plt.rcParams['figure.figsize'] = [12, 12]\n",
        "import random\n",
        "import copy\n",
        "#from ipywidgets import GridspecLayout, Button, Layout\n",
        "import math\n",
        "import numpy as np\n",
        "import sys\n",
        "from graphviz import Digraph\n",
        "import pylab\n",
        "\n",
        "import time\n",
        "import networkx as nx\n",
        "from networkx import *\n",
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "class Slot():\n",
        "\n",
        "    def __init__(self, word, is_core, page_destination):\n",
        "        '''\n",
        "        word : str que l'on souhaite traiter et placer sur la grille\n",
        "        is Core : Booléen un indiquant si le mot traité fait parti du vocabulaire core ou non\n",
        "        page_destination : page liée à ce slot\n",
        "        '''\n",
        "\n",
        "        self.__word = copy.copy(word)\n",
        "        self.__is_core = copy.copy(is_core)\n",
        "        self.__page_destination = copy.copy(page_destination)\n",
        "\n",
        "    # Accesseur\n",
        "    def get_word(self):\n",
        "\n",
        "        return self.__word\n",
        "\n",
        "    # Accesseur\n",
        "    def get_is_core(self):\n",
        "\n",
        "        return self.__is_core\n",
        "\n",
        "    def get_page_destination(self):\n",
        "\n",
        "        return self.__page_destination\n",
        "\n",
        "    def set_word(self, word):\n",
        "\n",
        "        self.__word = word\n",
        "\n",
        "    def set_page_destination(self, page):\n",
        "\n",
        "        self.__page_destination = page\n",
        "\n",
        "    def __str__(self):\n",
        "\n",
        "        dest = self.__page_destination\n",
        "        if dest:\n",
        "            dest = self.__page_destination.get_name()\n",
        "        # return '('+str(self.__word) + ';' + str(self.__is_core) + ';' + str(dest) + ')'\n",
        "        return f'{self.__word}({dest})'\n",
        "\n",
        "\n",
        "class Page():\n",
        "\n",
        "    #Constructor\n",
        "    def __init__(self, name, row_size, col_size):\n",
        "\n",
        "        self.__name = name\n",
        "        self.__row_size = row_size\n",
        "        self.__col_size = col_size\n",
        "        self.__full = False\n",
        "        self.__slots = []\n",
        "        self.__fill()\n",
        "        self.__last_R = 0\n",
        "        self.__last_C = 0\n",
        "\n",
        "    #Initialise chacun des slots à None\n",
        "    def __fill(self):\n",
        "\n",
        "      self.__slots = []\n",
        "      for i in range(0, self.__row_size) :\n",
        "        self.__slots.append([None])\n",
        "        for j in range(0, self.__col_size) :\n",
        "          self.__slots[i].append(None)\n",
        "\n",
        "    # Ajoute le Slot slot en position num_row, num_col et renvoie l'ancienne valeur\n",
        "    def set_slot(self, slot, num_row, num_col):\n",
        "\n",
        "      if (num_row >= self.__row_size) or (num_col >= self.__col_size):\n",
        "        print(f'row={num_row}, col={num_col}')\n",
        "        print(f'row_size={self.__row_size}, col_size={self.__col_size}')\n",
        "                \n",
        "        raise Exception('Error: slot row or col out of bounds') \n",
        "\n",
        "      old_value = self.__slots[num_row][num_col]\n",
        "      self.__slots[num_row][num_col] = slot\n",
        "\n",
        "      return old_value\n",
        "\n",
        "    def set_name(self, name):\n",
        "      self.__name = name\n",
        "\n",
        "      return name\n",
        "\n",
        "    # Accessors\n",
        "    def get_name(self):\n",
        "\n",
        "      return self.__name\n",
        "\n",
        "    def get_row_size(self):\n",
        "\n",
        "      return self.__row_size\n",
        "\n",
        "    def get_col_size(self):\n",
        "\n",
        "      return self.__col_size\n",
        "\n",
        "    def get_slot(self, num_row, num_col):\n",
        "\n",
        "      return self.__slots[num_row][num_col]\n",
        "\n",
        "    def get_slot_by_name(self, name):\n",
        "\n",
        "      for row in range(0, self.__row_size):\n",
        "        for col in range (0, self.__col_size):\n",
        "          slot = self.__slots[row][col]\n",
        "          if slot:          \n",
        "            if slot.get_word() == name:\n",
        "              return slot\n",
        "          \n",
        "      print(f'*** slot {name} not found in page {self.__name} ***')\n",
        "      return None\n",
        "    \n",
        "    def get_pictograms(self):\n",
        "\n",
        "      current_page_name = self.get_name()\n",
        "      attributes = {}\n",
        "      for row in range(0, self.__row_size):\n",
        "        for col in range (0, self.__col_size):\n",
        "          slot = self.__slots[row][col]\n",
        "          if slot:\n",
        "            word = slot.get_word()\n",
        "            dest = slot.get_page_destination()\n",
        "            if dest:\n",
        "              dest_page_name = dest.get_name()\n",
        "            else:\n",
        "              dest_page_name = None\n",
        "\n",
        "            id = f'{word}@{current_page_name}'\n",
        "            if id in attributes:\n",
        "              id = f'{id}**'\n",
        "\n",
        "            attributes[id] = [word, row, col, current_page_name, dest_page_name]  \n",
        "\n",
        "      return attributes\n",
        "      \n",
        "    # def get_slot_by_destination(self, dest):\n",
        "      \n",
        "    #   for row in range(0, self.__row_size):\n",
        "    #     for col in range (0, self.__col_size):\n",
        "    #       slot = self.__slots[row][col]\n",
        "    #       if slot:          \n",
        "    #         if slot.get_page_destination == dest:\n",
        "    #           return slot\n",
        "          \n",
        "    #   print(f'*** destination {dest} not found in any slot ofpage {self.__name} ***')\n",
        "    #   return None\n",
        "\n",
        "    def get_slot_list(self):\n",
        "\n",
        "      return self.__slots\n",
        "\n",
        "    #Return true if the slot at position (num_row, num_col) is free, false otherwise\n",
        "    def is_free(self, num_row, num_col):\n",
        "\n",
        "      return self.__slots[num_row][num_col] == None\n",
        "\n",
        "    #Return true if table is full, false otherwise\n",
        "    def is_full(self):\n",
        "\n",
        "      if (self.__full):\n",
        "        return True\n",
        "      for row in range(0, self.__row_size):\n",
        "        for col in range (0, self.__col_size):\n",
        "          if self.__slots[row][col] == None:\n",
        "            return False\n",
        "      self.__full = True\n",
        "      return True\n",
        "\n",
        "    def add_word(self, word, core=False, dest=None) :\n",
        "\n",
        "      if(self.__last_C == self.__col_size) : \n",
        "        self.__last_C = 0\n",
        "        self.__last_R += 1\n",
        "      if(self.__last_R == self.__row_size) :\n",
        "        self.__full = True\n",
        "        print(\"Failed to add word <\", word, \">. The table is full.\")\n",
        "        return None\n",
        "\n",
        "      if(self.__slots[self.__last_R][self.__last_C] == None) :\n",
        "\n",
        "        s = Slot(word, core, dest)\n",
        "        self.__slots[self.__last_R][self.__last_C] = s\n",
        "        self.__last_R\n",
        "        self.__last_C += 1\n",
        "        return word\n",
        "      \n",
        "      self.__last_R\n",
        "      self.__last_C += 1\n",
        "      return self.add_word(word, dest=dest)\n",
        "\n",
        "    # Méthode d'affichage (à revoir ? Efficacité chaînes de caractères)\n",
        "    def __str__(self):\n",
        "\n",
        "      s = \"Page: \" + self.__name + \"\\n(\"\n",
        "      for i in range(0, self.__row_size) : \n",
        "        for j in range(0, self.__col_size) :\n",
        "          s+=str(self.__slots[i][j])\n",
        "          s+=\", \"\n",
        "        s+='\\n'\n",
        "      return s+')'\n",
        "\n",
        "    # fonction auxiliaire pour l'affichage\n",
        "    # def create_expanded_button(self, description, button_style):\n",
        "\n",
        "    #   return Button(description=description, button_style=button_style,\n",
        "    #               layout=Layout(height='auto', width='auto'))\n",
        "       \n",
        "    # Affichage alternative (couteaux, debug)\n",
        "    # def show(self):\n",
        "\n",
        "    #   grid = GridspecLayout(self.__row_size, self.__col_size, width='50%')\n",
        "\n",
        "    #   for i in range(self.__row_size):\n",
        "    #     for j in range(self.__col_size):\n",
        "    #       # grid[i, j] = self.create_expanded_button('Button {} - {}'.format(i, j), 'success')\n",
        "    #       if self.__slots[i][j]:\n",
        "    #         content = str(self.__slots[i][j])\n",
        "    #       else:\n",
        "    #         content = ''\n",
        "    #       grid[i, j] = self.create_expanded_button(content, 'success')            \n",
        "\n",
        "\n",
        "    #   return grid\n",
        "\n",
        "\n",
        "## Grid\n",
        "class Grid():\n",
        "\n",
        "  #Constructor\n",
        "  def __init__(self, input_file, row_size, col_size):\n",
        "\n",
        "    self.__row_size = row_size\n",
        "    self.__col_size = col_size\n",
        "    self.__core_voc = {}\n",
        "    self.__pages = {}\n",
        "    self.__pageCounter = 0     \n",
        "    self.__fusion_id = 0\n",
        "    self.__create_grid(input_file)\n",
        "\n",
        "  #ToDo\n",
        "  def add_word(word):\n",
        "\n",
        "    return\n",
        "\n",
        "  def get_root_page(self):\n",
        "\n",
        "    return self.__pages.get('accueil')\n",
        "\n",
        "  # def __get_last_page(self):\n",
        "\n",
        "  #   return self.__pages[-1]\n",
        "  \n",
        "  def get_nb_pages(self):\n",
        "\n",
        "    return self.__pageCounter\n",
        "  \n",
        "  def get_page_names(self):\n",
        "\n",
        "    return self.__pages.keys()\n",
        "\n",
        "  def get_page(self, name):\n",
        "\n",
        "    return self.__pages.get(name) \n",
        "\n",
        "  def get_page_dict(self):\n",
        "\n",
        "    return self.__pages\n",
        "\n",
        "  def get_core_voc(self):\n",
        "\n",
        "    return self.__core_voc\n",
        "\n",
        "  def get_row_size(self):\n",
        "\n",
        "    return self.__row_size\n",
        "\n",
        "  def get_col_size(self):\n",
        "\n",
        "    return self.__col_size\n",
        "\n",
        "  # We assume that the word has not been already added\n",
        "  def add_word(self, word, dest=None):\n",
        "\n",
        "    # if self.__pages[-1].is_full() :\n",
        "\n",
        "    #   self.__add_page2()\n",
        "\n",
        "    # self.__pages[-1].add_word(word, dest=dest)\n",
        "\n",
        "    return\n",
        "  \n",
        "  def add_word_in_root(self, word, dest=None):\n",
        "\n",
        "    accueil_page = self.__pages.get('accueil')\n",
        "    if accueil_page.is_full() :\n",
        "\n",
        "      print('accueil complète, désolé')\n",
        "      return\n",
        "\n",
        "    accueil_page.add_word(word, dest=dest)\n",
        "\n",
        "    return\n",
        "\n",
        "  def add_new_page(self, name):\n",
        "\n",
        "    return self.__add_page(name)\n",
        "\n",
        "  def __add_page(self, name_page):\n",
        "\n",
        "    page = Page(name_page, self.__row_size, self.__col_size)    \n",
        "    self.__pages[name_page] = page\n",
        "    self.__pageCounter += 1 \n",
        "\n",
        "    return page\n",
        "\n",
        "  def update_leaf_picto(self, extra_page):\n",
        "    '''Recherche le premier pictogramme qui n'a pas de page de destination et mettre en place extra_page\n",
        "        comme destination. Renvoie la page contenant le picto trouvé'''\n",
        "\n",
        "    core_voc_dict = self.get_core_voc()\n",
        "\n",
        "    for page in self.get_page_dict().values():\n",
        "      if page.get_name() != extra_page.get_name():\n",
        "        for row in range(1, page.get_row_size()):\n",
        "          for col in range(1, page.get_col_size()):\n",
        "            slot = page.get_slot(row, col)\n",
        "            if slot:\n",
        "              if not slot.get_page_destination():\n",
        "                # slot.set_page_destination(extra_page)  ****\n",
        "                new_slot = Slot(slot.get_word(), False, extra_page)\n",
        "                page.set_slot(new_slot, row, col)\n",
        "\n",
        "                #m-à-j le tableau d'attributes\n",
        "                for key, picto in core_voc_dict.items():\n",
        "                  if picto[0] == slot.get_word() and picto[1] == row and picto[2] == col and picto[3] == page.get_name():\n",
        "                    \n",
        "                    picto[4] = extra_page.get_name()\n",
        "                                  \n",
        "                # print([(k,p) for k,p in core_voc_dict.items() if p[3] == 'accueil'])\n",
        "                return page\n",
        "\n",
        "\n",
        "  def __create_grid(self, input_file):\n",
        "    ''' Création d'une grille à partir d'un fichier texte ou d'un tableau d'attributes '''\n",
        "\n",
        "    #références pour le calcul de row_size, col_size et destination\n",
        "    row_ref = 0\n",
        "    col_ref = 0\n",
        "    first_page = None\n",
        "    last_id = None\n",
        "\n",
        "    # l'entrée est un dictionaire de pictogrammes\n",
        "    if isinstance(input_file, dict):\n",
        "      # print(\"Grille créée à partir d'un dictionaire de pictogrammes\")\n",
        "      # print()\n",
        "\n",
        "      self.__core_voc = dict(input_file)\n",
        "\n",
        "      # # obtenir row_size et col_size auprès de input_file\n",
        "      \n",
        "      # for picto in self.__core_voc.values():\n",
        "      #   row = int(picto[1])\n",
        "      #   column = int(picto[2])\n",
        "      #   page = picto[3]\n",
        "\n",
        "      #   if not first_page:\n",
        "      #         first_page = page\n",
        "\n",
        "      #   # determiner la taille de la grille\n",
        "      #   if page == first_page:\n",
        "      #     if row > row_ref:\n",
        "      #       row_ref = row\n",
        "      #     if column > col_ref:\n",
        "      #       col_ref = column\n",
        "      #   else:\n",
        "      #     break\n",
        "      \n",
        "      # self.__row_size = row_ref + 1\n",
        "      # self.__col_size = col_ref + 1\n",
        "\n",
        "    # l'entrée est un fichier .csv en format Augcom\n",
        "    elif input_file.endswith('.csv'):\n",
        "      # print(\"Grille créée à partir du fichier \" + input_file)\n",
        "      # print()\n",
        "\n",
        "      # Fichier brut à traiter\n",
        "      with open(input_file, \"r\") as rawFile:\n",
        "\n",
        "        #Traitement du fichier source\n",
        "        for lines in rawFile:\n",
        "          lines = lines.lower()\n",
        "          sentence = lines.strip()\n",
        "          col = sentence.split(\"\\t\")\t\t\n",
        "\n",
        "          # On gére le problème des lignes semi-vides créées par les liens entre les répertoires\n",
        "          if len(col) > 4:\n",
        "            \n",
        "            word = col[0]\n",
        "            row = int(col[1])\n",
        "            column = int(col[2])\n",
        "            page = col[3]\t\t\t\n",
        "            id = col[4]\n",
        "\n",
        "            # enregistrer le mot, les coordonnées, la page actuelle et la destination de chaque pictogramme\n",
        "            self.__core_voc[id] = [word, row, column, page, None]\n",
        "            \n",
        "            # if not first_page:\n",
        "            #   first_page = page\n",
        "\n",
        "            # # determiner la taille de la grille\n",
        "            # if page == first_page:\n",
        "            #   if row > row_ref:\n",
        "            #     row_ref = row\n",
        "            #   if column > col_ref:\n",
        "            #     col_ref = column\n",
        "            \n",
        "            last_id = id\n",
        "\n",
        "          # We recover the links between the directories\n",
        "          elif len(col) > 1:            \n",
        "            pointed_link = col[1]            \t\t\t\n",
        "            self.__core_voc.get(last_id)[4] = pointed_link\n",
        "      \n",
        "      # self.__row_size = row_ref + 1\n",
        "      # self.__col_size = col_ref + 1\n",
        "\n",
        "    else:\n",
        "      raise Exception('Incompatible input. Only dict (pictos attributes) or .csv files (augcom format) are accepted')\n",
        "\n",
        "    self.__add_core_voc()\n",
        "\n",
        "\n",
        "  def __add_core_voc(self):\n",
        "    \n",
        "    for picto in self.__core_voc.values():\n",
        "      word = picto[0]\n",
        "      row = picto[1]\n",
        "      col = picto[2]\n",
        "      page_name = picto[3]\n",
        "      dest_name = picto[4]\n",
        "\n",
        "      if page_name in self.__pages:\n",
        "        page = self.__pages.get(page_name)\n",
        "      else:\t\t  \n",
        "        page = self.__add_page(page_name)\n",
        "          \n",
        "      if dest_name:\n",
        "        if dest_name in self.__pages:\n",
        "          destination = self.__pages.get(dest_name)\n",
        "        else:\t\t\t\n",
        "          destination = self.__add_page(dest_name)          \n",
        "      else:\n",
        "        destination = None\n",
        "\n",
        "      slot = Slot(word, True, destination)    \n",
        "      page.set_slot(slot, row, col)\n",
        "\n",
        "  def to_graph(self):\n",
        "\n",
        "    nodes = set([])\n",
        "    edges = set([])\n",
        "    for key,page in self.__pages.items():\n",
        "      nodes.add(key)\n",
        "      slots = page.get_slot_list()\n",
        "      for items in slots:\n",
        "        for slot in items:\n",
        "          if slot != None:\n",
        "            dest = slot.get_page_destination()\n",
        "            if dest != None:\n",
        "              dest = dest.get_name()\n",
        "              edges.add((key, dest))\n",
        "    \n",
        "    G=nx.DiGraph()\n",
        "    G.add_nodes_from(nodes)\n",
        "    G.add_edges_from(edges)\n",
        "    nx.draw(G,with_labels=True)\n",
        "    # plt.savefig(\"grid_graph.png\") # save as png\n",
        "    plt.show() # display\n",
        "\n",
        "    return G\n",
        "\n",
        "  def cross_pages(self, page1, page2, parent=None):\n",
        "    ''' Croise page1 avec page2 et toutes les sous-pages analogues reliées aux page1 et page2.\n",
        "        'parent' identifie une page qui fait un appel récursive.\n",
        "        Renvoi 3 choses: \n",
        "        - Un tableau contenant les attributes des pictos dans la page résultante.\n",
        "        - La page résultante\n",
        "        - Un tableau contenant les pictos non affectés à la page résultante lors du croissement.\n",
        "\n",
        "        :parent: page de référence pour mettre en place les pictos de retour.\n",
        "    '''\n",
        "\n",
        "    # nous supposons que les deux pages ont la même taille\n",
        "    if page1:\n",
        "      row_size = page1.get_row_size()\n",
        "      col_size = page1.get_col_size()\n",
        "    elif page2:\n",
        "      row_size = page2.get_row_size()\n",
        "      col_size = page2.get_col_size()\n",
        "    \n",
        "    new_page_name_suffix = random.randint(0,1000)\n",
        "\n",
        "    # tableau de tous les attributs des pictogrammes de la page résultante\n",
        "    attributes = {}\n",
        "    # tableau des pictogrammes non affectés lors de la fusion\n",
        "    unallocated_pictos = {}\n",
        "\n",
        "    # cas 1: Aucune page n'existe\n",
        "    if (not page1) and (not page2):\n",
        "      # print('Rien a croiser, fin de la fonction')\n",
        "      \n",
        "      return {}, None, {}\n",
        "    \n",
        "    # cas 2: seul page1 existe\n",
        "    if page1 and (not page2):\n",
        "      result_page = copy.deepcopy(page1)\n",
        "      picto_dict = result_page.get_pictograms()\n",
        "\n",
        "      # # chercher et m-à-j le picto de retour.\n",
        "      # for picto in picto_dict.values():\n",
        "      #   if (picto[0] == 'retour_r') and (picto[1] == row_size - 1) and (picto[2] == col_size - 1):\n",
        "      #     if parent:\n",
        "      #       picto_dict[f'retour_r@{result_page.get_name()}'][4] = parent.get_name()\n",
        "      #       # print('Pictogram de retour mise à jour')\n",
        "      # attributes.update(picto_dict)\n",
        "      \n",
        "      # return attributes, result_page, {}\n",
        "\n",
        "      # m-à-j du picto_dict\n",
        "      for id, picto1 in picto_dict.items():\n",
        "            # réviser les duplicatas\n",
        "            if id in attributes:\n",
        "              id = f'{id}**'\n",
        "            \n",
        "            attributes[id] = picto1\n",
        "\n",
        "      for picto in picto_dict.values():\n",
        "        # chercher et m-à-j le picto de retour.\n",
        "        if (picto[0] == 'retour_r') and (picto[1] == row_size - 1) and (picto[2] == col_size - 1):\n",
        "          if parent:\n",
        "            picto_dict[f'retour_r@{result_page.get_name()}'][4] = parent.get_name()\n",
        "            # print('Pictogram de retour mise à jour')\n",
        "        else:\n",
        "          slot = result_page.get_slot(picto[1], picto[2])\n",
        "          dest = slot.get_page_destination()\n",
        "\n",
        "          #déterminer (recursivement) les pictos liés à la destination de chaque slot\n",
        "          attribs, selected_dest_page, unalloc = self.cross_pages(dest, None, result_page)\n",
        "\n",
        "          # m-à-j de attributes\n",
        "          for pict_id, picto2 in attribs.items():\n",
        "            # réviser les duplicatas\n",
        "            if pict_id in attributes:\n",
        "              pict_id = f'{pict_id}**'\n",
        "            \n",
        "            attributes[pict_id] = picto2  \n",
        "      \n",
        "      return attributes, result_page, {}      \n",
        "    \n",
        "    # cas 3: seul page2 existe\n",
        "    if page2 and (not page1):        \n",
        "      result_page = copy.deepcopy(page2) \n",
        "      picto_dict = result_page.get_pictograms()\n",
        "\n",
        "      # m-à-j du picto_dict\n",
        "      for id, picto1 in picto_dict.items():\n",
        "            # réviser les duplicatas\n",
        "            if id in attributes:\n",
        "              id = f'{id}**'\n",
        "            \n",
        "            attributes[id] = picto1\n",
        "\n",
        "      for picto in picto_dict.values():\n",
        "        # chercher et m-à-j le picto de retour.\n",
        "        if (picto[0] == 'retour_r') and (picto[1] == row_size - 1) and (picto[2] == col_size - 1):\n",
        "          if parent:\n",
        "            picto_dict[f'retour_r@{result_page.get_name()}'][4] = parent.get_name()\n",
        "            # print('Pictogram de retour mise à jour')\n",
        "        else:\n",
        "          slot = result_page.get_slot(picto[1], picto[2])\n",
        "          dest = slot.get_page_destination()\n",
        "\n",
        "          #déterminer (recursivement) les pictos liés à la destination de chaque slot\n",
        "          attribs, selected_dest_page, unalloc = self.cross_pages(None, dest, result_page)\n",
        "\n",
        "          # m-à-j de attributes\n",
        "          for pict_id, picto2 in attribs.items():\n",
        "            # réviser les duplicatas\n",
        "            if pict_id in attributes:\n",
        "              pict_id = f'{pict_id}**'\n",
        "            \n",
        "            attributes[pict_id] = picto2  \n",
        "      \n",
        "      return attributes, result_page, {}\n",
        "\n",
        "    # cas 4: les deux pages existent\n",
        "    if page1 and page2:\n",
        "\n",
        "      # décider le nom du page à retenir\n",
        "      if random.randint(0,1):\n",
        "        new_page_name = page1.get_name()\n",
        "      else:\n",
        "        new_page_name = page2.get_name()\n",
        "\n",
        "      # TO-DO: Vérifier si new_page_name existe déjà dans les pages selectionées. Deux solutions:  \n",
        "      # - ajouter suffixe au nom de la page pour la differencier des pages de base\n",
        "      # new_page_name += f'_{new_page_name_suffix}'\n",
        "      # où\n",
        "      # - Enregistrer les noms crées au fur et à mesure dans une liste, puis modifier légerement le nom si déjà dans la liste\n",
        "      # # ?? \n",
        "\n",
        "      #page résultante\n",
        "      result_page = Page(new_page_name, row_size, col_size)\n",
        "\n",
        "      #sélectionner les pictos qui vont populer la page résultante\n",
        "      for row in range(row_size):\n",
        "        for col in range(col_size):\n",
        "          slot_page1 = copy.deepcopy(page1.get_slot(row, col))\n",
        "          slot_page2 = copy.deepcopy(page2.get_slot(row, col))\n",
        "          random_selector = random.randint(0,1)\n",
        "\n",
        "          if (slot_page1) and (slot_page2):\n",
        "            dest_1 = slot_page1.get_page_destination()\n",
        "            dest_2 = slot_page2.get_page_destination()\n",
        "\n",
        "            if random_selector:\n",
        "              selected_slot = slot_page1\n",
        "              not_selected_slot = slot_page2\n",
        "              page_name = page1.get_name()\n",
        "              page_name_not_selected = page2.get_name()\n",
        "              \n",
        "            else:\n",
        "              selected_slot = slot_page2\n",
        "              not_selected_slot = slot_page1\n",
        "              page_name = page2.get_name()\n",
        "              page_name_not_selected = page1.get_name()\n",
        "\n",
        "            \n",
        "            #déterminer (recursivement) la destination du slot selectionné\n",
        "            if (selected_slot.get_word() != 'retour_r'):              \n",
        "              attribs, selected_dest_page, unalloc = self.cross_pages(dest_1, dest_2, result_page)\n",
        "\t\t\t      # picto de retour trouvé\n",
        "            elif (row == row_size - 1) and (col == col_size - 1):\n",
        "              attribs, selected_dest_page, unalloc = {}, parent, {}\n",
        "\n",
        "            #garder les pictos non affectés --------------------------------------\n",
        "            word_not_selected = not_selected_slot.get_word()\n",
        "            if word_not_selected != 'retour_r':\n",
        "              id_not_selected = f'{word_not_selected}@{page_name_not_selected}'\n",
        "\n",
        "              #si deux pictos non affectés ont le même id, modifier légerement l'id de l'un des deux\n",
        "              if id_not_selected in unallocated_pictos:\n",
        "                # '**' à la fin d'une id indiquera l'existence de 2 pictos differents avec la même mot et même nom de page \n",
        "                id_not_selected = f'{id_not_selected}**'            \n",
        "                        \n",
        "              unallocated_pictos[id_not_selected] = word_not_selected\n",
        "\n",
        "          elif slot_page1:\n",
        "            selected_slot = slot_page1\n",
        "            page_name = page1.get_name()\n",
        "\n",
        "            if selected_slot.get_word() != 'retour_r':\n",
        "              dest_1 = slot_page1.get_page_destination()\n",
        "              attribs, selected_dest_page, unalloc = self.cross_pages(dest_1, None, result_page)            \n",
        "            else:\n",
        "              if parent:\n",
        "                attribs, selected_dest_page, unalloc = {}, parent, {}              \n",
        "\n",
        "          elif slot_page2:\n",
        "            selected_slot = slot_page2\n",
        "            page_name = page2.get_name()\n",
        "\n",
        "            if selected_slot.get_word() != 'retour_r':\n",
        "              dest_2 = slot_page2.get_page_destination()\n",
        "              attribs, selected_dest_page, unalloc = self.cross_pages(dest_2, None, result_page)            \n",
        "            else:\n",
        "              if parent:\n",
        "                attribs, selected_dest_page, unalloc = {}, parent, {}\n",
        "            \n",
        "          # aucun des pictos n'existe\n",
        "          else: \n",
        "            selected_slot = None            \n",
        "\n",
        "          #m-à-j des attributes des pictogrammes de la page résultante\n",
        "          if selected_slot:\n",
        "            word = selected_slot.get_word()\n",
        "            selected_slot = Slot(word, False, selected_dest_page)\n",
        "            result_page.set_slot(selected_slot, row, col)\n",
        "\n",
        "            #ajouter les pictos des pages de destination\n",
        "            attributes.update(attribs)\n",
        "\n",
        "            #m-à-j le dict de pictos non affectés avec ceux des appels récursives\n",
        "            unallocated_pictos.update(unalloc)\n",
        "\n",
        "            id = f'{word}@{page_name}'\n",
        "\n",
        "            if selected_dest_page:                \n",
        "                dest_page_name = selected_dest_page.get_name()\n",
        "            else:\n",
        "              dest_page_name = None\n",
        "            #si deux pictos ont le même id, modifier légerement l'id de l'un d'eux\n",
        "            if id in attributes:\n",
        "              id = f'{word}@{page_name}**'\n",
        "            \n",
        "            attributes[id] = [word, row, col, new_page_name, dest_page_name]\n",
        "\n",
        "          # mettre en place le picto selectionné dans la page résultante \n",
        "          result_page.set_slot(selected_slot, row, col)     \n",
        "    \n",
        "    # print()\n",
        "    # if page1 and page2:\n",
        "    #   print(f'CROSSED: {page1.get_name()} <-> {page2.get_name()}')\n",
        "    # elif page1:\n",
        "    #   print(f'CROSSED: {page1.get_name()} <-> Nothing')\n",
        "    # else:\n",
        "    #   print(f'CROSSED: Nothing <-> {page2.get_name()}')\n",
        "\n",
        "    # print()\n",
        "    # for k,p in attributes.items():\n",
        "    #   print(f'{k}:{p}')\n",
        "    # print()\n",
        "\n",
        "    return attributes, result_page, unallocated_pictos\n",
        "  \n",
        "  def fusion_with(self, grid):\n",
        "    '''Fusione les pages analogues de deux grilles aléatoirement et renvoi la grille résultante. Elle contient\n",
        "      les pictogrammes des deux grilles'''\n",
        "\n",
        "    current_accueil = self.get_root_page() \n",
        "    foreing_accueil = grid.get_root_page()  \n",
        "\n",
        "    attributes_dict, result_page, unalloc_dict = self.cross_pages(current_accueil, foreing_accueil)    \n",
        "\n",
        "    # print('UNALLOCATED :\\n')\n",
        "    # print(unalloc_dict)\n",
        "  \n",
        "    row_size = self.get_row_size()\n",
        "    col_size = self.get_col_size()\n",
        "    new_grid = Grid(attributes_dict, row_size, col_size)\n",
        "\n",
        "    # print('--------------------------------------------')\n",
        "    # print(f'NEW_GRID AVANT REMPLISSAGE ET CRÉATION DES PAGES EXTRA')\n",
        "    # print()\n",
        "    # new_grid.display('before')\n",
        "    # for k,p in new_grid.get_core_voc().items():\n",
        "    #   print(f'{k}:{p}')\n",
        "    # print('------------------------------------------')\n",
        "    \n",
        "\n",
        "    # remplir slots vides avec les pictos non affectées\n",
        "    for page in new_grid.get_page_dict().values():\n",
        "      for row in range(1, row_size):\n",
        "        for col in range(1, col_size):\n",
        "          slot = page.get_slot(row, col)\n",
        "          if not slot:\n",
        "            # print(f'{slot}')\n",
        "            try:\n",
        "              # renvoyer l'id du pictgramme non affecté suivant\n",
        "              id_next_unalloc_picto = next(iter(unalloc_dict))\n",
        "\n",
        "              #vérifier si l'id du picto non alloué existe déjà dans le tableau d'attributes de la grille \n",
        "              if id_next_unalloc_picto in new_grid.get_core_voc():\n",
        "                new_id = f'{id_next_unalloc_picto}**'\n",
        "                unalloc_dict[new_id] = unalloc_dict.pop(id_next_unalloc_picto)\n",
        "                id_next_unalloc_picto = new_id\n",
        "\n",
        "              unalloc_picto = unalloc_dict.pop(id_next_unalloc_picto)\n",
        "              word = unalloc_picto\n",
        "              slot = Slot(word, False, None)\n",
        "              page.set_slot(slot, row, col)\n",
        "              \n",
        "              # print(f'slot vide affecté: page:{page.get_name()}, row: {row}, col: {col}, word: {word}')\n",
        "\n",
        "              #m-à-j du dict d'attriburtes de la nouvelle grille\n",
        "              new_grid.get_core_voc()[id_next_unalloc_picto] = [word, row, col, page.get_name(), None]     \n",
        "\n",
        "            # unalloc_dict est vide         \n",
        "            except:\n",
        "              print('** fusion complète 1 **')\n",
        "              return new_grid\n",
        "    \n",
        "    # gérer le cas où il y a plus de pictos non alloués que de slots vides.\n",
        "    while len(unalloc_dict):\n",
        "            \n",
        "      # créer et ajouter une page extra pour les allouer\n",
        "      extra_page_name = f'extra_{random.randint(0,10000)}'    \n",
        "      extra_page = new_grid.add_new_page(extra_page_name)\n",
        "\n",
        "      # choisir le picto connecté à la page extra. On parcours les pages en partant de l'accueil.\n",
        "      origin_page = new_grid.update_leaf_picto(extra_page)    \n",
        "\n",
        "      # mettre en place le picto de retour\n",
        "      if origin_page:\n",
        "        picto_retour = Slot('retour_r', False, origin_page)\n",
        "        extra_page.set_slot(picto_retour, row_size - 1, col_size - 1)\n",
        "        new_grid.get_core_voc()[f'retour_r@{extra_page_name}'] = ['retour_r', row_size - 1, col_size - 1, extra_page_name, origin_page.get_name()]\n",
        "      \n",
        "      # remplir slots vides de la PAGE EXTRA avec des pictos non affectées\n",
        "      for row in range(1, row_size):\n",
        "          for col in range(1, col_size):\n",
        "            slot = extra_page.get_slot(row, col)\n",
        "            # si le slot est vide\n",
        "            if not slot:\n",
        "              try:\n",
        "                # renvoyer l'id du pictgramme non affecté suivant\n",
        "                id_next_unalloc_picto = next(iter(unalloc_dict))\n",
        "\n",
        "                #vérifier si l'id du picto non alloué existe dans le dict d'attributes de la grille\n",
        "                # sinon, ajouter '**' à la fin de l'id répété pour en créér une autre \n",
        "                if id_next_unalloc_picto in new_grid.get_core_voc():\n",
        "                  new_id = f'{id_next_unalloc_picto}**'\n",
        "                  unalloc_dict[new_id] = unalloc_dict.pop(id_next_unalloc_picto)\n",
        "                  id_next_unalloc_picto = new_id\n",
        "\n",
        "                unalloc_picto = unalloc_dict.pop(id_next_unalloc_picto)\n",
        "                word = unalloc_picto\n",
        "                slot = Slot(word, False, None)\n",
        "                extra_page.set_slot(slot, row, col)\n",
        "\n",
        "                #m-à-j du dict d'attriburtes de la nouvelle grille\n",
        "                new_grid.get_core_voc()[id_next_unalloc_picto] = [word, row, col, extra_page.get_name(), None]              \n",
        "              except:\n",
        "                print('** fusion complète 2 **')                \n",
        "                return new_grid\n",
        "                \n",
        "    return new_grid\n",
        "\n",
        "  def shuffle(self):\n",
        "    '''Mélange les pictogrammes à l'intérieure de chaque page de la grille'''\n",
        "\n",
        "    core_voc_copy = copy.deepcopy(self.get_core_voc())\n",
        "    # new_grid_core_voc = new_grid.get_core_voc()\n",
        "    row_size = self.get_row_size()\n",
        "    col_size = self.get_col_size()\n",
        "\n",
        "    #créer liste de coordoneées de slots\n",
        "    all_coords = [(i,j) for i in range(1, row_size) for j in range(1, col_size)]\n",
        "    \n",
        "    #omettre le picto dans le coin en bas à droite (retour, plus, etc) \n",
        "    all_coords.pop()\n",
        "\n",
        "    for page_name in self.get_page_dict():\n",
        "      coords_list = list(all_coords)      \n",
        "      #mélange la liste\n",
        "      random.shuffle(coords_list)\n",
        "      info = []\n",
        "      c=0\n",
        "\n",
        "      for id, picto in self.get_core_voc().items():\n",
        "        \n",
        "        # choisir pictos dans la même page. Ne tenir pas compte des pictos en ligne/col = 0. \n",
        "        if (picto[3] == page_name) and (picto[1] != 0) and (picto[2] != 0):\n",
        "          info.append((id, picto))\n",
        "          if (picto[1] != row_size-1) or (picto[2] != col_size-1):     \n",
        "            \n",
        "            try:          \n",
        "              row, col = coords_list.pop()\n",
        "            except:\n",
        "              print('INFO_VOC:')\n",
        "              for i in info:\n",
        "                print(i)\n",
        "              print()\n",
        "              print('SELF_VOC:')\n",
        "              for k,i in self.get_core_voc().items():\n",
        "                print(k, i)\n",
        "                \n",
        "              self.display('shuffle_1')\n",
        "              raise Exception('PROBLEM')\n",
        "            # slot = Slot(picto[0], False, self.get_page(picto[4]))\n",
        "            # new_grid.get_page(page_name).set_slot(slot, row, col)\n",
        "\n",
        "            #affecter les nouvelles coordonnées aux pictos de la pag courante\n",
        "            core_voc_copy[id][1] = row\n",
        "            core_voc_copy[id][2] = col\n",
        "\n",
        "    \n",
        "    return Grid(core_voc_copy, row_size, col_size)\n",
        "\n",
        "  def to_text(self, output_name='grid_text.csv'):\n",
        "    '''Crée un fichier texte (.csv) décrivant la grille en format augcom'''\n",
        "\n",
        "    print(\"output file is \" + output_name)\n",
        "    print()\n",
        "    sorted_attrib_dict = {}\n",
        "\n",
        "    # trier le dict d'attributes par nom de page\n",
        "    for page_name in self.get_page_dict():     \n",
        "      for picto_id, attributes in self.get_core_voc().items():\n",
        "        if attributes[3] == page_name:\n",
        "          sorted_attrib_dict[picto_id] = self.get_core_voc().get(picto_id)       \n",
        "\n",
        "    # Fichier résultant\n",
        "    with open(output_name, \"w\") as text_file:\n",
        "      for picto_id, attributes in sorted_attrib_dict.items():\n",
        "        print(f'{attributes[0].upper()}\\t{attributes[1]}\\t{attributes[2]}\\t{attributes[3]}\\t{picto_id}', file=text_file) \n",
        "        if attributes[4]:\n",
        "          print(f'\\t\\t\\t{picto_id}\\t{attributes[4]}', file=text_file)\n",
        "\n",
        "  # Méthode d'affichage 1\n",
        "  def __str__(self):\n",
        "\n",
        "    s = 'grid : {\\n'\n",
        "    for page in self.__pages.values():\n",
        "      s+= str(page) + '\\n'\n",
        "    s += '}\\n'\n",
        "    return s\n",
        "\n",
        "  # Méthode d'affichage 2\n",
        "  def display(self, name='default'):\n",
        "    ''' Génére un image detaillé de l'estructure de la grille. Il utilise Graphviz et le language DOT'''\n",
        "\n",
        "    graph = Digraph(comment='Test', node_attr={'shape': 'record'}) #, 'fixedsize': 'true', 'width':'4', 'height':'2'})\n",
        "    row_size = self.get_row_size()\n",
        "    col_size = self.get_col_size()\n",
        "    slot_index = 0\n",
        "\n",
        "    for page_name,page in self.get_page_dict().items():\n",
        "      \n",
        "      attribute_string = '{ '\n",
        "      separator_1 = ''\n",
        "      for row in range(0, row_size):\n",
        "        separator_2 = ''\n",
        "        attribute_string += f'{separator_1}' + ' { '\n",
        "        for col in range(0, col_size):\n",
        "          slot_index  = row * col_size + col\n",
        "          slot = page.get_slot(row, col)\n",
        "\n",
        "          if slot:\n",
        "            word = slot.get_word()\n",
        "            dest = slot.get_page_destination()\n",
        "            #ajouter lien entre picto directoire et la page correspondante \n",
        "            if dest:              \n",
        "              graph.edge(f'{page_name}:{slot_index}', f'{dest.get_name()}')\n",
        "          elif row == 0 and col == 0:\n",
        "            word = page_name.upper()\n",
        "          else:\n",
        "            word = ''\n",
        "\n",
        "          attribute_string += f'{separator_2}<{slot_index}>{word} '\n",
        "          separator_2 = '|'\n",
        "\n",
        "        separator_1 = '|'\n",
        "        attribute_string += '} '\n",
        "      attribute_string += ' }'\n",
        "\n",
        "      #créer noeud \n",
        "      graph.node(f'{page_name}', f'{attribute_string}')\n",
        "      #print(graph.source)\n",
        "      graph.render(filename=name,format='png')\n",
        "\n",
        "      \n",
        "    return graph\n",
        "\n",
        "#****************************************************************************************************************\n",
        "\n",
        "def compute_distances(grid, movement_factor=1, selection_factor=1):\n",
        "  '''\n",
        "  Calcule la distance entre chaque paire de pictogrammes à l'intérieure de chaque page d'une grille\n",
        "  Prend en compte la difficulté du mouvement (movement_factor) et la difficulté de la sélection (selection_factor)\n",
        "  '''\n",
        "\n",
        "  # Dictionaire des distances\n",
        "  disTab = grid.get_core_voc()\n",
        "  # Copie du dict à utiliser dans la boucle interne\n",
        "  distTab_copy = copy.deepcopy(disTab) \n",
        "  # Final distances\n",
        "  distances = ''\n",
        "\n",
        "  # Définition du poids du mouvement\n",
        "  m = movement_factor\n",
        "  # Définition du poids du temps de sélection\n",
        "  n = selection_factor\n",
        "\n",
        "  for key1,picto1 in disTab.items():\n",
        "    # ID de référence\n",
        "    refID = key1\n",
        "    # On crée une variable qui prend comme valeur le nom de la page actuelle\n",
        "    currentPage = picto1[3]\n",
        "    # On récupere les coordonnées\n",
        "    x1 = picto1[1]\n",
        "    y1 = picto1[2]\n",
        "    # On enleve picto1 du deuxième dict\n",
        "    distTab_copy.pop(key1)\n",
        "    \n",
        "    for key2,picto2 in distTab_copy.items():\n",
        "      # ID de deuxième picto en question\n",
        "      ID = key2\n",
        "\n",
        "      # On vérifie que l'on est toujours sur la bonne page\n",
        "      currentPage2 = picto2[3]\n",
        "      x2 = picto2[1]\n",
        "      y2 = picto2[2]\n",
        "\n",
        "      if currentPage2 == currentPage:\n",
        "        # Si les deux IDs sont différents on récupère les coordonnées x et y de chacun\n",
        "        if refID != ID:\n",
        "          # Calcul des distances Euclidiennes\n",
        "          squaredDistance = (x1 - x2) ** 2 + (y1 - y2) ** 2\n",
        "          pictoDistance = math.sqrt(squaredDistance)\n",
        "\n",
        "          #Si le mot de d'arrivée de l'arc est un répertoire: C=(P1,P2)m\n",
        "          if \"_r@\" in ID :\n",
        "            #On écrit la fomule sans le n\n",
        "            distances += \"Mot à Répertoire\" + \"\\t\" + refID + \"\\t\" + ID + \"\\t\" + str(pictoDistance * m) + \"\\n\"\n",
        "\n",
        "          #Si le pictogarmme départ et celui d'arrivée sont des mots: C=(P1,P2)m+n            \n",
        "          else :\n",
        "            distances += \"Mot à Mot\" + \"\\t\" + refID + \"\\t\" + ID + \"\\t\" + str(pictoDistance * m + n) + \"\\n\"\n",
        "            distances += \"Mot à Mot\" + \"\\t\" + ID + \"\\t\" + refID + \"\\t\" + str(pictoDistance * m + n) + \"\\n\"\n",
        "\n",
        "    # On écrit le lien entre un pictogramme directeur (plus, retour, pagination, flèche retour et répertoires) et la page\n",
        "    if picto1[4]:\n",
        "      # Formule correspondnat uniquement à l'action de sélection: C=n\n",
        "      distances += \"Picto directeur à Page\" + \"\\t\" + refID + \"\\t\" + picto1[4] + \"\\t\" + str(n) + \"\\n\"\n",
        "\n",
        "    # On écrit le lien entre la page et le pictogramme \n",
        "    # On calcule la distance entre le lien de la page et des pictogrammes à partir du pictogramme en haut à gauche avec x=1 et y=1\n",
        "    squaredDistance3 = (1 - x1) ** 2 + (1 - y1) ** 2\n",
        "    pageToPicto = math.sqrt(squaredDistance3)\n",
        "\n",
        "    #Si le pictogramme d'arrivée de l'arc est un répetoire: C=(P(1,1)P2)m\n",
        "    if \"_r@\" in picto1[0] :\n",
        "      #On calcule sans le n\n",
        "      distances += \"Page à Répertoire\" + \"\\t\" + currentPage + \"\\t\" + picto1[0] + \"\\t\" + str(pageToPicto* m) + \"\\n\"\n",
        "    # Si le pictogramme d'arrivée est un mot: C=(P(1,1)P2)m+n\n",
        "    else :\n",
        "      distances += \"Page à Mot\" + \"\\t\" + currentPage + \"\\t\" + refID + \"\\t\" + str(pageToPicto * m + n) + \"\\n\"\n",
        "\n",
        "  # with open('dist_file.csv', \"w\") as dist:\n",
        "  #   for line in distances.splitlines():\n",
        "  #     dist.write(f'{line}\\n')\n",
        "\n",
        "  return distances\n",
        "\n",
        "#****************************************************************************************************************\n",
        "\n",
        "## Cost\n",
        "# FONCTIONS AUXILIAIRES POUR LE CALCUL DU COÛT DE PRODUCTION\n",
        "#--------------------------------------------------------------\n",
        "\n",
        "class WeightedPath:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.path = []\n",
        "        self.weight = 0\n",
        "\n",
        "\n",
        "# Fonction qui établit le noeud à partir duquel il faut commencer à calculer un arc\n",
        "'''\n",
        "text = texte d'entrée\n",
        "nodeList = liste de tous les noeuds du graphe\n",
        "edgeList = tableau associatif de tous les arcs avec en clé le noeud tête et en valeurs le noeud pointé et le poids de l'arc\n",
        "G = graphe initial (DiGraph)\n",
        "'''\n",
        "\n",
        "def initialNode(text, nodeList, edgeList, G):\n",
        "    path = []\n",
        "    stock = []\n",
        "    totalWeight = 0\n",
        "    startNode = \"accueil\"\n",
        "\n",
        "    # On parcours le fichier texte\n",
        "    for line in text.splitlines():\n",
        "        line = line.lower()\n",
        "        line = line.strip()\n",
        "        # On évite les lignes vides\n",
        "        if line != \"\":\n",
        "            # On récupère le plus court chemin\n",
        "            words = shortestPath(startNode, line, nodeList, edgeList, G)\n",
        "\n",
        "            # if words == -1:\n",
        "            #   return list([-1])\n",
        "\n",
        "            path = words.path\n",
        "            # On récupère le dernier élément de la liste\n",
        "            startNode = path[-1]\n",
        "            # On ajoute le poids\n",
        "            totalWeight += words.weight\n",
        "\n",
        "        finalPath = []\n",
        "        # On ajoute le premier élément de la liste au chemin final\n",
        "        finalPath.append(path[0])\n",
        "        # On parcours le chemin\n",
        "        for i in range(1, len(path)):\n",
        "            # Si on toruve deux mots qui se suivent différents\n",
        "            if path[i - 1] != path[i]:\n",
        "                # on ajoute l'elt au chemin final\n",
        "                finalPath.append(path[i])\n",
        "        # On stocke dans une liste le chemin et le poids total\n",
        "        # stock.append(str(finalPath) + \" \" + str(totalWeight))\n",
        "        stock.append((finalPath, totalWeight))\n",
        "\n",
        "    return stock\n",
        "\n",
        "\n",
        "# Fonction qui prend en entrée un mot de la phrase et en fait une liste de noeuds possibles\n",
        "'''\n",
        "nodeList = liste de tous les noeuds du graphe\n",
        "word = chaque word de la phrase d'entrée \n",
        "'''\n",
        "\n",
        "def textToNodes(word, nodeList):\n",
        "    candidatesNode = []\n",
        "    # on parcours la liste des noeuds\n",
        "    for i in range(0, len(nodeList)):\n",
        "        # on découpe au '@' pour récupérer le mot d'origine au lieu de l'identifiant complet\n",
        "        wordNode = nodeList[i].split(\"@\")\n",
        "        # Si le mot d'origine est égal au word de la phrase\n",
        "        if wordNode[0] == word:\n",
        "            # on l'ajoute à la liste des noeuds canidats potentiels\n",
        "            candidatesNode.append(nodeList[i])\n",
        "    return candidatesNode\n",
        "\n",
        "\n",
        "# Fonction de calcul du plus court path\n",
        "'''\n",
        "initialNode = point de départ de la recherche dans le graphe\n",
        "sentance = phrase d'entrée pour laquelle il faut calculer le cout de production\n",
        "nodeList = liste de tous les noeuds du graphe\n",
        "edgeList = tableau associatif de tous les arcs avec en clé le noeud tête et en valeurs le noeud pointé et le weight de l'arc\n",
        "'''\n",
        "\n",
        "def shortestPath(initialNode, sentance, nodeList, edgeList, G):\n",
        "    initialNodes = []\n",
        "    words = sentance.split(\" \")\n",
        "    shortestPath = []\n",
        "    # Initialisation du poids total\n",
        "    totalWeight = 0\n",
        "    initialNodes.append(initialNode)\n",
        "    \n",
        "    # On créé la variable du chemin final\n",
        "    finalPath = []\n",
        "    pathList = []\n",
        "\n",
        "    # On créé un nouveau graphe avec la liste des candidats\n",
        "    coupleGraphe = nx.DiGraph()\n",
        "    # coupleGraphe.add_node(\"end\")\n",
        "\n",
        "    index = 0\n",
        "    # On parcours la phrase\n",
        "    for word in words:\n",
        "        minWeight = 10000\n",
        "        # On stocke dans une variable les mots \"candidats\" pour créer le plus court chemin        \n",
        "        candidates = textToNodes(word, nodeList)\n",
        "\n",
        "        # Pour chaque candidat\n",
        "        for candidate in candidates:\n",
        "            # On ajoute les candidats comme noeuds du sous graphe\n",
        "            coupleGraphe.add_node(candidate)\n",
        "\n",
        "            # Quand on arrive à l fin d ela phrase\n",
        "            if index == len(words) - 1:\n",
        "                # On créé un arc \"end\" de poids 0\n",
        "                coupleGraphe.add_edge(candidate, \"end\", weight=0)\n",
        "            elif index == 0:\n",
        "                # On créé un arc \"accueil\" de poids 0\n",
        "                coupleGraphe.add_edge(\"accueil\", candidate, weight=0)\n",
        "\n",
        "            # On parcours la liste des noeuds initiaux\n",
        "            for firstNode in initialNodes:\n",
        "                # On extrait le plus court chemin entre le premier noeud et le candidat avec la fonctionn \"shortest_path \"fonction Networkx\n",
        "                try:\n",
        "                    # graph = Digraph(filename='GGGG',format='png',comment='TEST_1')\n",
        "                    path = nx.shortest_path(G, source=firstNode, target=candidate)\n",
        "                except nx.NetworkXNoPath:\n",
        "                    \n",
        "                    print (\"No path between %s and %s.\" % (firstNode, candidate))\n",
        "\n",
        "                    # return -1\n",
        "\n",
        "                    # plt.clf()\n",
        "                    # pos = nx.spring_layout(G, k=0.85, iterations=20)                    \n",
        "                    # nx.draw(G, pos, edge_color='magenta', width = 0.5, node_size=60, with_labels=True)\n",
        "                    # time.sleep(60)\n",
        "\n",
        "\n",
        "                # On initialise le poids\n",
        "                weight = 0\n",
        "                # On parcours le chemin\n",
        "                for i in range(1, len(path)):\n",
        "                    edgePrevNode = edgeList[path[i - 1]]\n",
        "                    for edge in edgePrevNode:\n",
        "                        # On vérifie que le premier elt de la variable arc = shortest path de i\n",
        "                        if edge[0] == path[i]:\n",
        "                            weight += edge[1]                                                        \n",
        "\n",
        "                # Si le poids est inférieur au poids minimum\n",
        "                if weight < minWeight:\n",
        "                    # Le poids min prend la valeur du poids\n",
        "                    minWeight = weight\n",
        "\n",
        "                pathList.append(path)\n",
        "\n",
        "                coupleGraphe.add_edge(path[0], path[-1], weight=weight)\n",
        "                \n",
        "        # On modifie le point de départ de la fonction\n",
        "        initialNodes = candidates\n",
        "        index = index + 1\n",
        "\n",
        "        # On calcule la somme des poids entre les arcs\n",
        "        totalWeight += minWeight\n",
        "\n",
        "        # print(f'MinWeight = {minWeight}')  \n",
        "    \n",
        "    # On applique à nouveau une recherche du plus court chemin dans le sous graphe\n",
        "    try:        \n",
        "        shortestpath = nx.shortest_path(coupleGraphe, source=\"accueil\", target=\"end\")\n",
        "    except nx.NetworkXNoPath:\n",
        "\n",
        "        print (\"No path between %s and %s. Please check the input phrase\" % (\"accueil\", \"end\"))\n",
        "        sys.exit()\n",
        "        \n",
        "    # On céé le chemin final\n",
        "    wordIndex = 0\n",
        "    # On parcours la liste des chemins\n",
        "    for path in pathList:\n",
        "        if (shortestpath[wordIndex] == path[0]) and (shortestpath[wordIndex + 1] == path[-1]):\n",
        "            for words in path:\n",
        "                finalPath.append(words)\n",
        "            wordIndex = wordIndex + 1\n",
        "    \n",
        "    # On créé un objet\n",
        "    weightedPath = WeightedPath()\n",
        "    weightedPath.path = finalPath\n",
        "    weightedPath.weight = totalWeight\n",
        "\n",
        "    return weightedPath\n",
        "\n",
        "# Fonction qui stocke un objet dans un fichier .pkl\n",
        "'''\n",
        "obj = lobjet à stocker\n",
        "name = nom du fichier créé\n",
        "'''\n",
        "\n",
        "def save_obj(obj, name ):\n",
        "    with open(name + '.pkl', 'wb') as f:\n",
        "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# Fonction qui récupere un objet contenu dans un fichier .pkl\n",
        "'''\n",
        "name = nom du fichier cible\n",
        "'''\n",
        "\n",
        "def load_obj(name ):\n",
        "    with open(name + '.pkl', 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "#****************************************************************************************************************\n",
        "\n",
        "def compute_cost(input_sentence, distances):\n",
        "  # start_time = time.time()\n",
        "\n",
        "  # variable qui garde le meilleur chemin et le coût final\n",
        "  result = []\n",
        "      \n",
        "  # # On créé le graph G\n",
        "  graph = nx.DiGraph()\n",
        "\n",
        "  # tableau associatif (dict) qui comprendra les noeuds et les poids\n",
        "  edgeList = {}\n",
        "\n",
        "  # # On parcours les distances pour déterminer les noeuds, les arcs et les poids\n",
        "  for line in distances.splitlines():\n",
        "      line = line.strip()\n",
        "      col = line.split('\\t')\n",
        "      \n",
        "      # Addition du noeud au graphe\n",
        "      graph.add_node(col[1])\n",
        "\n",
        "      # Création des arcs avec leurs poids\n",
        "      graph.add_edge(col[1], col[2], weight=col[3])\n",
        "\n",
        "      # Création du tableau associatif \n",
        "      if col[1] in edgeList.keys():\n",
        "          edgeList[col[1]].append((col[2], float(col[3])))\n",
        "      else:\n",
        "          edgeList[col[1]] = [(col[2], float(col[3]))]\n",
        "\n",
        "  # création de la liste des noeuds\n",
        "  nodeList = list(graph.nodes())\n",
        "\n",
        "  output = initialNode(input_sentence, nodeList, edgeList, graph)\n",
        "\n",
        "  # Sauvegarde des résultats\n",
        "  for elt in output:\n",
        "      result.append(elt)      \n",
        "\n",
        "  # print(\"--- %s seconds ---\" % '{:5.5}'.format(time.time() - start_time))\n",
        "\n",
        "  return result\n",
        "\n",
        "#****************************************************************************************************************\n",
        "\n",
        "# ALGORITHME GÉNÉTIQUE\n",
        "from deap import base\n",
        "from deap import creator\n",
        "from deap import tools\n",
        "\n",
        "# CX_PROB  est la probabilité avec laquelle deux individus se croisent\n",
        "# MUT_PROB est la probabilité de mutation d'un individu\n",
        "CX_PROB, MUT_PROB = 0.9, 0.9    ## todo: choisir les probs\n",
        "\n",
        "# SCORE_THRESHOLD est le coût ciblé.\n",
        "# MAX_ITER est le nombre maximale d'itérations\n",
        "SCORE_THRESHOLD, MAX_ITER = 7.0, 5\n",
        "\n",
        "# Dimensions des grilles\n",
        "ROW_SIZE = 4\n",
        "COL_SIZE = 4\n",
        "\n",
        "# phrase d'entrée\n",
        "# sentence = 'je voyager train'\n",
        "sentence = 'je voyager train'\n",
        "\n",
        "def init_grid(container, source_file):\n",
        "  \n",
        "  return container(source_file, ROW_SIZE, ROW_SIZE)\n",
        "\n",
        "def init_population(container, func, source_file_list):\n",
        "  \n",
        "  return container(func(file) for file in source_file_list)\n",
        "\n",
        "#Créer le container pour la fonction de coût et les individus\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))      ##todo: arrange weights quand plusieurs fitnesses (sentences) \n",
        "creator.create(\"Individual\", Grid, fitness=creator.FitnessMax, best_path=[])\n",
        "\n",
        "# Initialisateurs\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register(\"individual\", init_grid, creator.Individual)\n",
        "toolbox.register(\"population\", init_population, list, toolbox.individual)\n",
        "\n",
        "# Fonction d'évaluation du coût de production\n",
        "def evalProdCost(sentence, individual):\n",
        "  distances = compute_distances(individual)\n",
        "  cost = compute_cost(sentence, distances)\n",
        "  # path = result[0][0]\n",
        "  # cost = result[0][1]\n",
        "  \n",
        "  individual.best_path = cost[0][0]\n",
        "  \n",
        "  # if len(cost) == 1:\n",
        "  #   if cost[0] == -1:\n",
        "  #     print([(k,p) for k,p in individual.get_core_voc().items()])\n",
        "  #     return individual.display('bug')\n",
        "          \n",
        "  return cost[0][1],    ##todo: plusieurs sentences\n",
        "\n",
        "# Fonction de fusion externe(fusion)\n",
        "def external_fusion(individual1, individual2):\n",
        "  # print('INDIVIDUAL 1 ************************')\n",
        "  # print(individual1)\n",
        "  # for k,p in individual1.get_core_voc().items():\n",
        "  #   print(f'{k}:{p}')\n",
        "  # print()\n",
        "  # individual1.display('ind_1')\n",
        "  # print('INDIVIDUAL 2 ************************')\n",
        "  # print(individual2)\n",
        "  # for k,p in individual2.get_core_voc().items():\n",
        "  #   print(f'{k}:{p}')\n",
        "  # print()\n",
        "  # individual2.display('ind_2')\n",
        "  # print('NEW GRID ****************************')\n",
        "  new_grid = individual1.fusion_with(individual2)\n",
        "  # print()\n",
        "  # print(new_grid)\n",
        "  # for k,p in new_grid.get_core_voc().items():\n",
        "  #   print(f'{k}:{p}')\n",
        "  # print()\n",
        "  # new_grid.display('new_ind')\n",
        "\n",
        "  \n",
        "  # input(\"Press Enter to continue...\")\n",
        "\n",
        "  return toolbox.individual(new_grid.get_core_voc())\n",
        "\n",
        "# Fonction de fusion interne (shuffle)\n",
        "def internal_fusion(individual):\n",
        "  new_grid = individual.shuffle()\n",
        "\n",
        "  return toolbox.individual(new_grid.get_core_voc())\n",
        "\n",
        "# Operateurs génétiques\n",
        "toolbox.register(\"evaluate\", evalProdCost, sentence)\n",
        "toolbox.register(\"mate\", external_fusion)\n",
        "toolbox.register(\"mutate\", internal_fusion)\n",
        "toolbox.register(\"select\", tools.selBest)\n",
        "\n",
        "\n",
        "#****************************************************************************************************************\n",
        "#PIPEPLINE\n",
        "\n",
        "def main(files):\n",
        "  #Création de la population\n",
        "  pop = toolbox.population(files)\n",
        "\n",
        "  # Évaluer l'ensemble de la population\n",
        "  fitnesses = list(map(toolbox.evaluate, pop))\n",
        "  for ind, fit in zip(pop, fitnesses):\n",
        "    ind.fitness.values = fit\n",
        "\n",
        "  # Effectuer l'évolution\n",
        "\n",
        "  # Extraction de toutes les fitnesses\n",
        "  fits = [ind.fitness.values[0] for ind in pop]\n",
        "\n",
        "  # # Extraction de tous les chemins optimales\n",
        "  # optimal_paths = [ind]\n",
        "\n",
        "  # Variable permettant de suivre le nombre de générations\n",
        "  g = 0\n",
        "\n",
        "  # Commencez l'évolution ***\n",
        "\n",
        "  # évoluer jusqu'à ce qu'un individu atteigne SCORE_THRESHOLD ou que le nombre de générations atteigne MAX_ITER\n",
        "  while max(fits) > SCORE_THRESHOLD and g < MAX_ITER:\n",
        "    # A new generation\n",
        "    g = g + 1\n",
        "    print(\"-- Generation %i --\" % g)\n",
        "\n",
        "    # Sélectionnez les individus de la génération suivante\n",
        "    offspring = toolbox.select(pop, len(pop))\n",
        "\n",
        "    # Cloner les individus sélectionnés\n",
        "    #offspring = list(map(toolbox.clone, offspring))\n",
        "\n",
        "    # Appliquer le crossover et la mutation sur la progéniture ***\n",
        "\n",
        "    new_cx_individuals = []\n",
        "    for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
        "      if random.random() < CX_PROB:\n",
        "        n_ind = toolbox.mate(child1, child2)\n",
        "\n",
        "        new_cx_individuals.append(n_ind)\n",
        "\n",
        "        # check_missing(n_ind)\n",
        "        \n",
        "        # del child1.fitness.values\n",
        "        # del child2.fitness.values\n",
        "\n",
        "    # m-à-j offspring    \n",
        "    offspring.extend(new_cx_individuals)\n",
        "\n",
        "    new_mut_individuals = []\n",
        "    for mutant in offspring:\n",
        "      if random.random() < MUT_PROB:\n",
        "        n_ind = toolbox.mutate(mutant)\n",
        "        new_mut_individuals.append(n_ind)\n",
        "\n",
        "    #     # check_voc(n_ind.get_core_voc())\n",
        "    #     # del mutant.fitness.values\n",
        "\n",
        "    # m-à-j offspring \n",
        "    offspring.extend(new_mut_individuals)\n",
        "\n",
        "    # Evaluer les individus sans fitness calculée (fitness invalide) ***\n",
        "    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
        "    fitnesses = map(toolbox.evaluate, invalid_ind)\n",
        "    for ind, fit in zip(invalid_ind, fitnesses):\n",
        "      ind.fitness.values = fit\n",
        "\n",
        "    # print(*[i.fitness.values for i in offspring])\n",
        "\n",
        "    # remplacer l'ancienne population par la descendance\n",
        "    pop = offspring\n",
        "\n",
        "  # Rassemblez tous les fitness dans une liste et imprimez les statistiques\n",
        "  fits = [ind.fitness.values[0] for ind in pop]\n",
        "            \n",
        "  length = len(pop)\n",
        "  mean = sum(fits) / length\n",
        "  sum2 = sum(x*x for x in fits)\n",
        "  std = abs(sum2 / length - mean**2)**0.5\n",
        "\n",
        "  # indice de l'individu avec la fitness la plus optimale\n",
        "  index_min = np.argmin(fits)\n",
        "\n",
        "  # indice de l'individu avec la pire fitness\n",
        "  index_max = np.argmax(fits)\n",
        "\n",
        "  ind_min = pop[index_min]\n",
        "  ind_max = pop[index_max]\n",
        "\n",
        "  \n",
        "\n",
        "  c = 0\n",
        "  print()\n",
        "  for ind in pop:\n",
        "    print(f'Path_{c}: {ind.best_path}')\n",
        "    ind.display(f'img/ind_{c}')\n",
        "    c+=1\n",
        "  print()\n",
        "\n",
        "  # ind_min.display('MIN')\n",
        "  # ind_max.display('MAX')\n",
        "\n",
        "  print()\n",
        "  print(fits)\n",
        "  print()\n",
        "\n",
        "  print(\"  Min %s\" % min(fits))\n",
        "  print(\"  Max %s\" % max(fits))\n",
        "  print(\"  Avg %s\" % mean)\n",
        "  print(\"  Std %s\" % std)\n",
        "\n",
        "\n",
        "#****************************************************************************************************************\n",
        "\n",
        "\n",
        "# TESTING\n",
        "## TEST PIPELINE\n",
        "\n",
        "path1 = '/home/fran/mosig/internship/grid_gen/testing/'\n",
        "\n",
        "# noms des fichiers texte (corpus) de chaque grille \n",
        "files = [f'{path1}grid_1_3p_raw.csv', f'{path1}grid_2_3p_raw.csv', f'{path1}grid_3_6p_raw.csv', f'{path1}grid_4_2p_raw.csv']\n",
        "\n",
        "# files = [f'{path1}g1_letters.csv', f'{path1}g2_letters.csv']\n",
        "# files = [f'{path1}grid_1_3p_raw.csv', f'{path2}Corrected_proloquo_FR_brut.csv']\n",
        "\n",
        "main(files)\n",
        "\n",
        "#****************************************************************************************************************\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/fran/.local/lib/python3.8/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
            "/home/fran/.local/lib/python3.8/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Generation 1 --\n",
            "** fusion complète 1 **\n",
            "** fusion complète 2 **\n",
            "-- Generation 2 --\n",
            "** fusion complète 2 **\n",
            "** fusion complète 2 **\n",
            "** fusion complète 1 **\n",
            "** fusion complète 2 **\n",
            "** fusion complète 2 **\n",
            "INFO_VOC:\n",
            "('train@sport', ['train', 1, 1, 'sport', None])\n",
            "('velo@sport', ['velo', 1, 2, 'sport', None])\n",
            "('je@sport', ['je', 2, 3, 'sport', None])\n",
            "('animaux_r@sport', ['animaux_r', 2, 1, 'sport', None])\n",
            "('chien@sport', ['chien', 2, 2, 'sport', None])\n",
            "('voyager@sport', ['voyager', 2, 3, 'sport', None])\n",
            "('tennis@sport', ['tennis', 2, 2, 'sport', None])\n",
            "('moto@sport', ['moto', 3, 2, 'sport', None])\n",
            "('retour_r@sport', ['retour_r', 3, 3, 'sport', 'animaux'])\n",
            "('velo@accueil', ['velo', 1, 3, 'sport', None])\n",
            "\n",
            "SELF_VOC:\n",
            "femme@accueil ['femme', 1, 1, 'accueil', 'extra_1348']\n",
            "chaise@accueil ['chaise', 1, 2, 'accueil', None]\n",
            "camion@accueil ['camion', 1, 3, 'accueil', None]\n",
            "salade@extra_666 ['salade', 2, 2, 'extra_666', None]\n",
            "viande@extra_666 ['viande', 3, 2, 'extra_666', None]\n",
            "retour_r@extra_666 ['retour_r', 3, 3, 'extra_666', 'accueil']\n",
            "train@accueil ['train', 2, 1, 'accueil', 'extra_666']\n",
            "moto@accueil ['moto', 2, 2, 'accueil', None]\n",
            "toilette@accueil ['toilette', 2, 3, 'accueil', None]\n",
            "bus@accueil ['bus', 3, 1, 'accueil', None]\n",
            "bureau@accueil ['bureau', 3, 2, 'accueil', None]\n",
            "train@sport ['train', 1, 1, 'sport', None]\n",
            "velo@sport ['velo', 1, 2, 'sport', None]\n",
            "je@sport ['je', 2, 3, 'sport', None]\n",
            "animaux_r@sport ['animaux_r', 2, 1, 'sport', None]\n",
            "chien@sport ['chien', 2, 2, 'sport', None]\n",
            "voyager@sport ['voyager', 2, 3, 'sport', None]\n",
            "tennis@sport ['tennis', 2, 2, 'sport', None]\n",
            "moto@sport ['moto', 3, 2, 'sport', None]\n",
            "retour_r@sport ['retour_r', 3, 3, 'sport', 'animaux']\n",
            "chat@animaux ['chat', 1, 1, 'animaux', 'sport']\n",
            "je@animaux ['je', 1, 2, 'animaux', None]\n",
            "carrote@animaux ['carrote', 1, 3, 'animaux', None]\n",
            "chat@animaux** ['chat', 2, 1, 'animaux', 'sport']\n",
            "voyager@animaux ['voyager', 2, 2, 'animaux', None]\n",
            "sport_r@animaux ['sport_r', 2, 3, 'animaux', None]\n",
            "salle@animaux ['salle', 3, 1, 'animaux', None]\n",
            "avion@animaux ['avion', 3, 2, 'animaux', None]\n",
            "retour_r@animaux ['retour_r', 3, 3, 'animaux', 'accueil']\n",
            "plus_r@accueil ['plus_r', 3, 3, 'accueil', 'animaux']\n",
            "je@accueil ['je', 1, 1, 'extra_666', None]\n",
            "bus@accueil** ['bus', 1, 2, 'extra_666', None]\n",
            "camion@accueil** ['camion', 1, 3, 'extra_666', None]\n",
            "avion@accueil ['avion', 2, 1, 'extra_666', None]\n",
            "je@accueil** ['je', 2, 3, 'extra_666', None]\n",
            "voyager@accueil ['voyager', 3, 1, 'extra_666', None]\n",
            "velo@accueil ['velo', 1, 3, 'sport', None]\n",
            "train@accueil** ['train', 3, 1, 'sport', None]\n",
            "retour_r@extra_1348 ['retour_r', 3, 3, 'extra_1348', 'accueil']\n",
            "animaux_r@accueil ['animaux_r', 1, 1, 'extra_1348', None]\n",
            "chien@animaux ['chien', 1, 2, 'extra_1348', None]\n",
            "sport_r@animaux** ['sport_r', 1, 3, 'extra_1348', None]\n",
            "avion@animaux** ['avion', 2, 1, 'extra_1348', None]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "PROBLEM",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-92c829782fb3>\u001b[0m in \u001b[0;36mshuffle\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    892\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m               \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoords_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: pop from empty list",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-92c829782fb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1554\u001b[0m \u001b[0;31m# files = [f'{path1}grid_1_3p_raw.csv', f'{path2}Corrected_proloquo_FR_brut.csv']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1556\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1558\u001b[0m \u001b[0;31m#****************************************************************************************************************\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-92c829782fb3>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(files)\u001b[0m\n\u001b[1;32m   1480\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmutant\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moffspring\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mMUT_PROB\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m         \u001b[0mn_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmutant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1483\u001b[0m         \u001b[0mnew_mut_individuals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-92c829782fb3>\u001b[0m in \u001b[0;36minternal_fusion\u001b[0;34m(individual)\u001b[0m\n\u001b[1;32m   1412\u001b[0m \u001b[0;31m# Fonction de fusion interne (shuffle)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minternal_fusion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindividual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1414\u001b[0;31m   \u001b[0mnew_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindividual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1416\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindividual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_core_voc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-92c829782fb3>\u001b[0m in \u001b[0;36mshuffle\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shuffle_1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PROBLEM'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;31m# slot = Slot(picto[0], False, self.get_page(picto[4]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0;31m# new_grid.get_page(page_name).set_slot(slot, row, col)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: PROBLEM"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *****************************************************************************************************"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "[20.65685424949238, 15.70820393249937, 15.70820393249937, 15.70820393249937, 15.70820393249937,\n",
        "12.70820393249937, 11.06449510224598, 10.650281539872886, 10.650281539872886, 10.650281539872886,\n",
        "10.23606797749979, 10.23606797749979, 9.650281539872886, 7.650281539872885, 6.650281539872885,\n",
        "5.82842712474619, 5.82842712474619, 5.82842712474619, 5.82842712474619, 13.70820393249937,\n",
        "10.23606797749979, 11.886349517372675, 10.650281539872886, 9.650281539872886, 8.650281539872886,\n",
        "7.650281539872885, 5.82842712474619]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "source": [
        "g1=Grid('testing/grid_3_6p_raw.csv', 4,4)\n",
        "g1.display()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"576pt\" height=\"359pt\"\n viewBox=\"0.00 0.00 575.50 359.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 355)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-355 571.5,-355 571.5,4 -4,4\"/>\n<!-- accueil -->\n<g id=\"node1\" class=\"node\">\n<title>accueil</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"201,-258.5 201,-350.5 378,-350.5 378,-258.5 201,-258.5\"/>\n<text text-anchor=\"middle\" x=\"243.5\" y=\"-335.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ACCUEIL</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"286,-327.5 286,-350.5 \"/>\n<text text-anchor=\"middle\" x=\"301.5\" y=\"-335.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"317,-327.5 317,-350.5 \"/>\n<text text-anchor=\"middle\" x=\"332\" y=\"-335.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"347,-327.5 347,-350.5 \"/>\n<text text-anchor=\"middle\" x=\"362.5\" y=\"-335.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"201,-327.5 378,-327.5 \"/>\n<text text-anchor=\"middle\" x=\"212\" y=\"-312.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"223,-304.5 223,-327.5 \"/>\n<text text-anchor=\"middle\" x=\"258.5\" y=\"-312.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">maison_r</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"294,-304.5 294,-327.5 \"/>\n<text text-anchor=\"middle\" x=\"311\" y=\"-312.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">fin</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"328,-304.5 328,-327.5 \"/>\n<text text-anchor=\"middle\" x=\"353\" y=\"-312.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">avion</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"201,-304.5 378,-304.5 \"/>\n<text text-anchor=\"middle\" x=\"211\" y=\"-289.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"221,-281.5 221,-304.5 \"/>\n<text text-anchor=\"middle\" x=\"251\" y=\"-289.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">voyager</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"281,-281.5 281,-304.5 \"/>\n<text text-anchor=\"middle\" x=\"301.5\" y=\"-289.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">livre</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"322,-281.5 322,-304.5 \"/>\n<text text-anchor=\"middle\" x=\"350\" y=\"-289.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ecole_r</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"201,-281.5 378,-281.5 \"/>\n<text text-anchor=\"middle\" x=\"211.5\" y=\"-266.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"222,-258.5 222,-281.5 \"/>\n<text text-anchor=\"middle\" x=\"249.5\" y=\"-266.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">garcon</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"277,-258.5 277,-281.5 \"/>\n<text text-anchor=\"middle\" x=\"299\" y=\"-266.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">table</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"321,-258.5 321,-281.5 \"/>\n<text text-anchor=\"middle\" x=\"349.5\" y=\"-266.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">lieux_r</text>\n</g>\n<!-- maison -->\n<g id=\"node2\" class=\"node\">\n<title>maison</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"0,-129.5 0,-221.5 163,-221.5 163,-129.5 0,-129.5\"/>\n<text text-anchor=\"middle\" x=\"39.5\" y=\"-206.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">MAISON</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"79,-198.5 79,-221.5 \"/>\n<text text-anchor=\"middle\" x=\"93\" y=\"-206.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"107,-198.5 107,-221.5 \"/>\n<text text-anchor=\"middle\" x=\"121\" y=\"-206.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"135,-198.5 135,-221.5 \"/>\n<text text-anchor=\"middle\" x=\"149\" y=\"-206.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"0,-198.5 163,-198.5 \"/>\n<text text-anchor=\"middle\" x=\"10.5\" y=\"-183.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"21,-175.5 21,-198.5 \"/>\n<text text-anchor=\"middle\" x=\"31.5\" y=\"-183.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"42,-175.5 42,-198.5 \"/>\n<text text-anchor=\"middle\" x=\"70\" y=\"-183.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cuisine</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"98,-175.5 98,-198.5 \"/>\n<text text-anchor=\"middle\" x=\"130.5\" y=\"-183.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">chambre</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"0,-175.5 163,-175.5 \"/>\n<text text-anchor=\"middle\" x=\"20\" y=\"-160.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"40,-152.5 40,-175.5 \"/>\n<text text-anchor=\"middle\" x=\"60.5\" y=\"-160.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"81,-152.5 81,-175.5 \"/>\n<text text-anchor=\"middle\" x=\"101.5\" y=\"-160.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"122,-152.5 122,-175.5 \"/>\n<text text-anchor=\"middle\" x=\"142.5\" y=\"-160.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"0,-152.5 163,-152.5 \"/>\n<text text-anchor=\"middle\" x=\"10\" y=\"-137.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"20,-129.5 20,-152.5 \"/>\n<text text-anchor=\"middle\" x=\"44\" y=\"-137.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">savon</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"68,-129.5 68,-152.5 \"/>\n<text text-anchor=\"middle\" x=\"85.5\" y=\"-137.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">eau</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"103,-129.5 103,-152.5 \"/>\n<text text-anchor=\"middle\" x=\"133\" y=\"-137.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">retour_r</text>\n</g>\n<!-- accueil&#45;&gt;maison -->\n<g id=\"edge1\" class=\"edge\">\n<title>accueil:5&#45;&gt;maison</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M247.7835,-304.1589C236.7766,-291.8181 218.848,-272.622 201.5,-258 189.1734,-247.6103 175.5423,-237.2779 162.0214,-227.6188\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"163.8182,-224.6031 153.6296,-221.6972 159.7823,-230.3225 163.8182,-224.6031\"/>\n</g>\n<!-- ecole -->\n<g id=\"node3\" class=\"node\">\n<title>ecole</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"403.5,-129.5 403.5,-221.5 567.5,-221.5 567.5,-129.5 403.5,-129.5\"/>\n<text text-anchor=\"middle\" x=\"439\" y=\"-206.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ECOLE</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"474.5,-198.5 474.5,-221.5 \"/>\n<text text-anchor=\"middle\" x=\"490\" y=\"-206.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"505.5,-198.5 505.5,-221.5 \"/>\n<text text-anchor=\"middle\" x=\"521\" y=\"-206.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"536.5,-198.5 536.5,-221.5 \"/>\n<text text-anchor=\"middle\" x=\"552\" y=\"-206.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"403.5,-198.5 567.5,-198.5 \"/>\n<text text-anchor=\"middle\" x=\"413.5\" y=\"-183.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"423.5,-175.5 423.5,-198.5 \"/>\n<text text-anchor=\"middle\" x=\"460\" y=\"-183.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">professeur</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"496.5,-175.5 496.5,-198.5 \"/>\n<text text-anchor=\"middle\" x=\"522\" y=\"-183.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">devoir</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"547.5,-175.5 547.5,-198.5 \"/>\n<text text-anchor=\"middle\" x=\"557.5\" y=\"-183.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"403.5,-175.5 567.5,-175.5 \"/>\n<text text-anchor=\"middle\" x=\"420\" y=\"-160.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"436.5,-152.5 436.5,-175.5 \"/>\n<text text-anchor=\"middle\" x=\"468.5\" y=\"-160.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cahier</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"500.5,-152.5 500.5,-175.5 \"/>\n<text text-anchor=\"middle\" x=\"517\" y=\"-160.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"533.5,-152.5 533.5,-175.5 \"/>\n<text text-anchor=\"middle\" x=\"550.5\" y=\"-160.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"403.5,-152.5 567.5,-152.5 \"/>\n<text text-anchor=\"middle\" x=\"418\" y=\"-137.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"432.5,-129.5 432.5,-152.5 \"/>\n<text text-anchor=\"middle\" x=\"450.5\" y=\"-137.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">je</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"468.5,-129.5 468.5,-152.5 \"/>\n<text text-anchor=\"middle\" x=\"483\" y=\"-137.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"497.5,-129.5 497.5,-152.5 \"/>\n<text text-anchor=\"middle\" x=\"532.5\" y=\"-137.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">retour_r</text>\n</g>\n<!-- accueil&#45;&gt;ecole -->\n<g id=\"edge2\" class=\"edge\">\n<title>accueil:11&#45;&gt;ecole</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M378.5,-292.5C415.0773,-292.5 442.5118,-260.9758 460.4397,-230.6542\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"463.603,-232.1704 465.4706,-221.7415 457.507,-228.7295 463.603,-232.1704\"/>\n</g>\n<!-- lieux -->\n<g id=\"node4\" class=\"node\">\n<title>lieux</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"181.5,-129.5 181.5,-221.5 385.5,-221.5 385.5,-129.5 181.5,-129.5\"/>\n<text text-anchor=\"middle\" x=\"220.5\" y=\"-206.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">LIEUX</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"259.5,-198.5 259.5,-221.5 \"/>\n<text text-anchor=\"middle\" x=\"280.5\" y=\"-206.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"301.5,-198.5 301.5,-221.5 \"/>\n<text text-anchor=\"middle\" x=\"322.5\" y=\"-206.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"343.5,-198.5 343.5,-221.5 \"/>\n<text text-anchor=\"middle\" x=\"364.5\" y=\"-206.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"181.5,-198.5 385.5,-198.5 \"/>\n<text text-anchor=\"middle\" x=\"204.5\" y=\"-183.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"227.5,-175.5 227.5,-198.5 \"/>\n<text text-anchor=\"middle\" x=\"250.5\" y=\"-183.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"273.5,-175.5 273.5,-198.5 \"/>\n<text text-anchor=\"middle\" x=\"296.5\" y=\"-183.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"319.5,-175.5 319.5,-198.5 \"/>\n<text text-anchor=\"middle\" x=\"352.5\" y=\"-183.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">parc</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"181.5,-175.5 385.5,-175.5 \"/>\n<text text-anchor=\"middle\" x=\"201\" y=\"-160.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"220.5,-152.5 220.5,-175.5 \"/>\n<text text-anchor=\"middle\" x=\"240.5\" y=\"-160.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"260.5,-152.5 260.5,-175.5 \"/>\n<text text-anchor=\"middle\" x=\"303\" y=\"-160.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">hopital_r</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"345.5,-152.5 345.5,-175.5 \"/>\n<text text-anchor=\"middle\" x=\"365.5\" y=\"-160.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"181.5,-152.5 385.5,-152.5 \"/>\n<text text-anchor=\"middle\" x=\"191.5\" y=\"-137.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"201.5,-129.5 201.5,-152.5 \"/>\n<text text-anchor=\"middle\" x=\"236.5\" y=\"-137.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">universite</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"271.5,-129.5 271.5,-152.5 \"/>\n<text text-anchor=\"middle\" x=\"298.5\" y=\"-137.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">agence</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"325.5,-129.5 325.5,-152.5 \"/>\n<text text-anchor=\"middle\" x=\"355.5\" y=\"-137.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">retour_r</text>\n</g>\n<!-- accueil&#45;&gt;lieux -->\n<g id=\"edge3\" class=\"edge\">\n<title>accueil:15&#45;&gt;lieux</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M349.5,-258.5C349.5,-248.6621 346.6242,-239.3148 342.0732,-230.6819\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"344.9558,-228.6855 336.7745,-221.9536 338.9721,-232.3181 344.9558,-228.6855\"/>\n</g>\n<!-- maison&#45;&gt;accueil -->\n<g id=\"edge4\" class=\"edge\">\n<title>maison:15&#45;&gt;accueil</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M163.5,-140.5C181.7212,-140.5 163.2366,-206.3092 172.5,-222 179.0449,-233.086 187.731,-243.0633 197.4241,-251.9267\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"195.1596,-254.5957 205.0138,-258.4874 199.7373,-249.3 195.1596,-254.5957\"/>\n</g>\n<!-- ecole&#45;&gt;accueil -->\n<g id=\"edge5\" class=\"edge\">\n<title>ecole:15&#45;&gt;accueil</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M532.5,-129.5C532.5,-129.5 567.5,-222 567.5,-222 545.6069,-251.3338 458.8921,-273.9613 388.0579,-288.0368\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"387.3207,-284.6145 378.1766,-289.9659 388.662,-291.4848 387.3207,-284.6145\"/>\n</g>\n<!-- lieux&#45;&gt;accueil -->\n<g id=\"edge7\" class=\"edge\">\n<title>lieux:15&#45;&gt;accueil</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M355.5,-129.5C355.5,-129.5 385.5,-222 385.5,-222 380.6773,-232.5035 373.7842,-242.1733 365.8751,-250.9087\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"363.1233,-248.7196 358.6896,-258.3421 368.1563,-253.5847 363.1233,-248.7196\"/>\n</g>\n<!-- hopital -->\n<g id=\"node5\" class=\"node\">\n<title>hopital</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"179,-.5 179,-92.5 356,-92.5 356,-.5 179,-.5\"/>\n<text text-anchor=\"middle\" x=\"221\" y=\"-77.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">HOPITAL</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"263,-69.5 263,-92.5 \"/>\n<text text-anchor=\"middle\" x=\"278.5\" y=\"-77.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"294,-69.5 294,-92.5 \"/>\n<text text-anchor=\"middle\" x=\"309.5\" y=\"-77.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"325,-69.5 325,-92.5 \"/>\n<text text-anchor=\"middle\" x=\"340.5\" y=\"-77.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"179,-69.5 356,-69.5 \"/>\n<text text-anchor=\"middle\" x=\"190\" y=\"-54.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"201,-46.5 201,-69.5 \"/>\n<text text-anchor=\"middle\" x=\"212\" y=\"-54.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"223,-46.5 223,-69.5 \"/>\n<text text-anchor=\"middle\" x=\"259.5\" y=\"-54.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">infirmiere</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"296,-46.5 296,-69.5 \"/>\n<text text-anchor=\"middle\" x=\"326\" y=\"-54.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">docteur</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"179,-46.5 356,-46.5 \"/>\n<text text-anchor=\"middle\" x=\"189\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"199,-23.5 199,-46.5 \"/>\n<text text-anchor=\"middle\" x=\"227\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pacient</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"255,-23.5 255,-46.5 \"/>\n<text text-anchor=\"middle\" x=\"285\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">maladie</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"315,-23.5 315,-46.5 \"/>\n<text text-anchor=\"middle\" x=\"335.5\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">train</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"179,-23.5 356,-23.5 \"/>\n<text text-anchor=\"middle\" x=\"196\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"213,-.5 213,-23.5 \"/>\n<text text-anchor=\"middle\" x=\"230\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"247,-.5 247,-23.5 \"/>\n<text text-anchor=\"middle\" x=\"264\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"281,-.5 281,-23.5 \"/>\n<text text-anchor=\"middle\" x=\"318.5\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">retour_r</text>\n</g>\n<!-- lieux&#45;&gt;hopital -->\n<g id=\"edge6\" class=\"edge\">\n<title>lieux:10&#45;&gt;hopital</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M300.0482,-152.2815C296.4514,-140.5922 290.54,-121.38 284.7349,-102.5134\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"288.0078,-101.249 281.7217,-92.7205 281.3174,-103.3076 288.0078,-101.249\"/>\n</g>\n<!-- hopital&#45;&gt;lieux -->\n<g id=\"edge8\" class=\"edge\">\n<title>hopital:15&#45;&gt;lieux</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M356.5,-11.5C392.7222,-11.5 369.3344,-59.1278 356.5,-93 352.7126,-102.9956 347.0994,-112.559 340.6382,-121.4025\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"337.8638,-119.2688 334.4941,-129.3135 343.3923,-123.5626 337.8638,-119.2688\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7fa9bcbd08b0>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "source": [
        "g2=g1.shuffle()\n",
        "g2.display()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VOC_AVANT: \n",
            "{'maison_r@accueil': ['maison_r', 1, 1, 'accueil', 'maison'], 'voyager@accueil': ['voyager', 2, 1, 'accueil', None], 'garcon@accueil': ['garcon', 3, 1, 'accueil', None], 'fin@accueil': ['fin', 1, 2, 'accueil', None], 'livre@accueil': ['livre', 2, 2, 'accueil', None], 'table@accueil': ['table', 3, 2, 'accueil', None], 'avion@accueil': ['avion', 1, 3, 'accueil', None], 'ecole_r@accueil': ['ecole_r', 2, 3, 'accueil', 'ecole'], 'lieux_r@accueil': ['lieux_r', 3, 3, 'accueil', 'lieux'], 'chambre@maison': ['chambre', 1, 3, 'maison', None], 'cuisine@maison': ['cuisine', 1, 2, 'maison', None], 'savon@maison': ['savon', 3, 1, 'maison', None], 'eau@maison': ['eau', 3, 2, 'maison', None], 'retour_r@maison': ['retour_r', 3, 3, 'maison', 'accueil'], 'parc@lieux': ['parc', 1, 3, 'lieux', None], 'hopital_r@lieux': ['hopital_r', 2, 2, 'lieux', 'hopital'], 'universite@lieux': ['universite', 3, 1, 'lieux', None], 'agence@lieux': ['agence', 3, 2, 'lieux', None], 'retour_r@lieux': ['retour_r', 3, 3, 'lieux', 'accueil'], 'infirmiere@hopital': ['infirmiere', 1, 2, 'hopital', None], 'docteur@hopital': ['docteur', 1, 3, 'hopital', None], 'pacient@hopital': ['pacient', 2, 1, 'hopital', None], 'maladie@hopital': ['maladie', 2, 2, 'hopital', None], 'train@hopital': ['train', 2, 3, 'hopital', None], 'retour_r@hopital': ['retour_r', 3, 3, 'hopital', 'lieux'], 'professeur@ecole': ['professeur', 1, 1, 'ecole', None], 'cahier@ecole': ['cahier', 2, 1, 'ecole', None], 'je@ecole': ['je', 3, 1, 'ecole', None], 'devoir@ecole': ['devoir', 1, 2, 'ecole', None], 'retour_r@ecole': ['retour_r', 3, 3, 'ecole', 'accueil']}\n",
            "VOC_APRES: \n",
            "{'maison_r@accueil': ['maison_r', 1, 3, 'accueil', 'maison'], 'voyager@accueil': ['voyager', 3, 2, 'accueil', None], 'garcon@accueil': ['garcon', 2, 1, 'accueil', None], 'fin@accueil': ['fin', 2, 2, 'accueil', None], 'livre@accueil': ['livre', 1, 2, 'accueil', None], 'table@accueil': ['table', 1, 1, 'accueil', None], 'avion@accueil': ['avion', 2, 3, 'accueil', None], 'ecole_r@accueil': ['ecole_r', 3, 1, 'accueil', 'ecole'], 'lieux_r@accueil': ['lieux_r', 3, 3, 'accueil', 'lieux'], 'chambre@maison': ['chambre', 2, 1, 'maison', None], 'cuisine@maison': ['cuisine', 2, 3, 'maison', None], 'savon@maison': ['savon', 2, 2, 'maison', None], 'eau@maison': ['eau', 1, 2, 'maison', None], 'retour_r@maison': ['retour_r', 3, 3, 'maison', 'accueil'], 'parc@lieux': ['parc', 2, 2, 'lieux', None], 'hopital_r@lieux': ['hopital_r', 1, 3, 'lieux', 'hopital'], 'universite@lieux': ['universite', 3, 1, 'lieux', None], 'agence@lieux': ['agence', 1, 1, 'lieux', None], 'retour_r@lieux': ['retour_r', 3, 3, 'lieux', 'accueil'], 'infirmiere@hopital': ['infirmiere', 2, 1, 'hopital', None], 'docteur@hopital': ['docteur', 2, 2, 'hopital', None], 'pacient@hopital': ['pacient', 3, 2, 'hopital', None], 'maladie@hopital': ['maladie', 1, 2, 'hopital', None], 'train@hopital': ['train', 2, 3, 'hopital', None], 'retour_r@hopital': ['retour_r', 3, 3, 'hopital', 'lieux'], 'professeur@ecole': ['professeur', 2, 2, 'ecole', None], 'cahier@ecole': ['cahier', 1, 1, 'ecole', None], 'je@ecole': ['je', 2, 3, 'ecole', None], 'devoir@ecole': ['devoir', 3, 1, 'ecole', None], 'retour_r@ecole': ['retour_r', 3, 3, 'ecole', 'accueil']}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"567pt\" height=\"359pt\"\n viewBox=\"0.00 0.00 567.15 359.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 355)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-355 563.1466,-355 563.1466,4 -4,4\"/>\n<!-- accueil -->\n<g id=\"node1\" class=\"node\">\n<title>accueil</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"165,-258.5 165,-350.5 356,-350.5 356,-258.5 165,-258.5\"/>\n<text text-anchor=\"middle\" x=\"209.5\" y=\"-335.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ACCUEIL</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"254,-327.5 254,-350.5 \"/>\n<text text-anchor=\"middle\" x=\"271\" y=\"-335.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"288,-327.5 288,-350.5 \"/>\n<text text-anchor=\"middle\" x=\"305\" y=\"-335.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"322,-327.5 322,-350.5 \"/>\n<text text-anchor=\"middle\" x=\"339\" y=\"-335.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"165,-327.5 356,-327.5 \"/>\n<text text-anchor=\"middle\" x=\"177\" y=\"-312.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"189,-304.5 189,-327.5 \"/>\n<text text-anchor=\"middle\" x=\"213\" y=\"-312.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">table</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"237,-304.5 237,-327.5 \"/>\n<text text-anchor=\"middle\" x=\"260\" y=\"-312.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">livre</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"283,-304.5 283,-327.5 \"/>\n<text text-anchor=\"middle\" x=\"319.5\" y=\"-312.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">maison_r</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"165,-304.5 356,-304.5 \"/>\n<text text-anchor=\"middle\" x=\"179.5\" y=\"-289.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"194,-281.5 194,-304.5 \"/>\n<text text-anchor=\"middle\" x=\"225.5\" y=\"-289.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">garcon</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"257,-281.5 257,-304.5 \"/>\n<text text-anchor=\"middle\" x=\"278\" y=\"-289.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">fin</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"299,-281.5 299,-304.5 \"/>\n<text text-anchor=\"middle\" x=\"327.5\" y=\"-289.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">avion</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"165,-281.5 356,-281.5 \"/>\n<text text-anchor=\"middle\" x=\"175\" y=\"-266.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"185,-258.5 185,-281.5 \"/>\n<text text-anchor=\"middle\" x=\"213\" y=\"-266.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ecole_r</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"241,-258.5 241,-281.5 \"/>\n<text text-anchor=\"middle\" x=\"271\" y=\"-266.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">voyager</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"301,-258.5 301,-281.5 \"/>\n<text text-anchor=\"middle\" x=\"328.5\" y=\"-266.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">lieux_r</text>\n</g>\n<!-- maison -->\n<g id=\"node2\" class=\"node\">\n<title>maison</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"169,-129.5 169,-221.5 356,-221.5 356,-129.5 169,-129.5\"/>\n<text text-anchor=\"middle\" x=\"211.5\" y=\"-206.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">MAISON</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"254,-198.5 254,-221.5 \"/>\n<text text-anchor=\"middle\" x=\"271\" y=\"-206.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"288,-198.5 288,-221.5 \"/>\n<text text-anchor=\"middle\" x=\"305\" y=\"-206.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"322,-198.5 322,-221.5 \"/>\n<text text-anchor=\"middle\" x=\"339\" y=\"-206.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"169,-198.5 356,-198.5 \"/>\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-183.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"212,-175.5 212,-198.5 \"/>\n<text text-anchor=\"middle\" x=\"233.5\" y=\"-183.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"255,-175.5 255,-198.5 \"/>\n<text text-anchor=\"middle\" x=\"284\" y=\"-183.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">eau</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"313,-175.5 313,-198.5 \"/>\n<text text-anchor=\"middle\" x=\"334.5\" y=\"-183.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"169,-175.5 356,-175.5 \"/>\n<text text-anchor=\"middle\" x=\"179\" y=\"-160.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"189,-152.5 189,-175.5 \"/>\n<text text-anchor=\"middle\" x=\"221\" y=\"-160.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">chambre</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"253,-152.5 253,-175.5 \"/>\n<text text-anchor=\"middle\" x=\"277\" y=\"-160.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">savon</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"301,-152.5 301,-175.5 \"/>\n<text text-anchor=\"middle\" x=\"328.5\" y=\"-160.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cuisine</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"169,-152.5 356,-152.5 \"/>\n<text text-anchor=\"middle\" x=\"187\" y=\"-137.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"205,-129.5 205,-152.5 \"/>\n<text text-anchor=\"middle\" x=\"223.5\" y=\"-137.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"242,-129.5 242,-152.5 \"/>\n<text text-anchor=\"middle\" x=\"260.5\" y=\"-137.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"279,-129.5 279,-152.5 \"/>\n<text text-anchor=\"middle\" x=\"317.5\" y=\"-137.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">retour_r</text>\n</g>\n<!-- accueil&#45;&gt;maison -->\n<g id=\"edge1\" class=\"edge\">\n<title>accueil:7&#45;&gt;maison</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M356.5,-316.5C382.5,-316.5 367.2258,-281.6845 356.5,-258 351.7889,-247.5971 345.0461,-237.9866 337.3052,-229.2819\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"339.6934,-226.7139 330.2716,-221.8683 334.6152,-231.5318 339.6934,-226.7139\"/>\n</g>\n<!-- ecole -->\n<g id=\"node3\" class=\"node\">\n<title>ecole</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"0,-129.5 0,-221.5 151,-221.5 151,-129.5 0,-129.5\"/>\n<text text-anchor=\"middle\" x=\"33.5\" y=\"-206.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ECOLE</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"67,-198.5 67,-221.5 \"/>\n<text text-anchor=\"middle\" x=\"81\" y=\"-206.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"95,-198.5 95,-221.5 \"/>\n<text text-anchor=\"middle\" x=\"109\" y=\"-206.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"123,-198.5 123,-221.5 \"/>\n<text text-anchor=\"middle\" x=\"137\" y=\"-206.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"0,-198.5 151,-198.5 \"/>\n<text text-anchor=\"middle\" x=\"15\" y=\"-183.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"30,-175.5 30,-198.5 \"/>\n<text text-anchor=\"middle\" x=\"60\" y=\"-183.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cahier</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"90,-175.5 90,-198.5 \"/>\n<text text-anchor=\"middle\" x=\"105\" y=\"-183.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"120,-175.5 120,-198.5 \"/>\n<text text-anchor=\"middle\" x=\"135.5\" y=\"-183.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"0,-175.5 151,-175.5 \"/>\n<text text-anchor=\"middle\" x=\"11.5\" y=\"-160.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"23,-152.5 23,-175.5 \"/>\n<text text-anchor=\"middle\" x=\"34.5\" y=\"-160.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"46,-152.5 46,-175.5 \"/>\n<text text-anchor=\"middle\" x=\"84\" y=\"-160.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">professeur</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"122,-152.5 122,-175.5 \"/>\n<text text-anchor=\"middle\" x=\"136.5\" y=\"-160.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">je</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"0,-152.5 151,-152.5 \"/>\n<text text-anchor=\"middle\" x=\"10\" y=\"-137.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"20,-129.5 20,-152.5 \"/>\n<text text-anchor=\"middle\" x=\"45.5\" y=\"-137.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">devoir</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"71,-129.5 71,-152.5 \"/>\n<text text-anchor=\"middle\" x=\"81\" y=\"-137.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"91,-129.5 91,-152.5 \"/>\n<text text-anchor=\"middle\" x=\"121\" y=\"-137.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">retour_r</text>\n</g>\n<!-- accueil&#45;&gt;ecole -->\n<g id=\"edge2\" class=\"edge\">\n<title>accueil:13&#45;&gt;ecole</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M212.5,-258.5C212.5,-254.7512 188.1874,-239.4314 160.0464,-222.9547\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"161.6164,-219.8189 151.2127,-217.8157 158.0964,-225.8695 161.6164,-219.8189\"/>\n</g>\n<!-- lieux -->\n<g id=\"node4\" class=\"node\">\n<title>lieux</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"374.5,-129.5 374.5,-221.5 544.5,-221.5 544.5,-129.5 374.5,-129.5\"/>\n<text text-anchor=\"middle\" x=\"409.5\" y=\"-206.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">LIEUX</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"444.5,-198.5 444.5,-221.5 \"/>\n<text text-anchor=\"middle\" x=\"461\" y=\"-206.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"477.5,-198.5 477.5,-221.5 \"/>\n<text text-anchor=\"middle\" x=\"494\" y=\"-206.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"510.5,-198.5 510.5,-221.5 \"/>\n<text text-anchor=\"middle\" x=\"527.5\" y=\"-206.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"374.5,-198.5 544.5,-198.5 \"/>\n<text text-anchor=\"middle\" x=\"385.5\" y=\"-183.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"396.5,-175.5 396.5,-198.5 \"/>\n<text text-anchor=\"middle\" x=\"425\" y=\"-183.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">agence</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"453.5,-175.5 453.5,-198.5 \"/>\n<text text-anchor=\"middle\" x=\"465\" y=\"-183.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"476.5,-175.5 476.5,-198.5 \"/>\n<text text-anchor=\"middle\" x=\"510.5\" y=\"-183.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">hopital_r</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"374.5,-175.5 544.5,-175.5 \"/>\n<text text-anchor=\"middle\" x=\"393\" y=\"-160.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"411.5,-152.5 411.5,-175.5 \"/>\n<text text-anchor=\"middle\" x=\"430.5\" y=\"-160.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"449.5,-152.5 449.5,-175.5 \"/>\n<text text-anchor=\"middle\" x=\"478\" y=\"-160.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">parc</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"506.5,-152.5 506.5,-175.5 \"/>\n<text text-anchor=\"middle\" x=\"525.5\" y=\"-160.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"374.5,-152.5 544.5,-152.5 \"/>\n<text text-anchor=\"middle\" x=\"384.5\" y=\"-137.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"394.5,-129.5 394.5,-152.5 \"/>\n<text text-anchor=\"middle\" x=\"429.5\" y=\"-137.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">universite</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"464.5,-129.5 464.5,-152.5 \"/>\n<text text-anchor=\"middle\" x=\"474.5\" y=\"-137.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"484.5,-129.5 484.5,-152.5 \"/>\n<text text-anchor=\"middle\" x=\"514.5\" y=\"-137.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">retour_r</text>\n</g>\n<!-- accueil&#45;&gt;lieux -->\n<g id=\"edge3\" class=\"edge\">\n<title>accueil:15&#45;&gt;lieux</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M356.5,-269.5C384.2995,-269.5 407.8836,-250.5871 425.4406,-229.7281\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"428.3668,-231.6726 431.8706,-221.6739 422.8963,-227.3052 428.3668,-231.6726\"/>\n</g>\n<!-- maison&#45;&gt;accueil -->\n<g id=\"edge4\" class=\"edge\">\n<title>maison:15&#45;&gt;accueil</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M317.5,-129.5C317.5,-129.5 356,-222 356,-222 351.2052,-232.4782 344.3498,-242.1332 336.4827,-250.8609\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"333.7466,-248.6566 329.3352,-258.2894 338.7908,-253.51 333.7466,-248.6566\"/>\n</g>\n<!-- ecole&#45;&gt;accueil -->\n<g id=\"edge5\" class=\"edge\">\n<title>ecole:15&#45;&gt;accueil</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M151.5,-140.5C169.7212,-140.5 151.8365,-205.9702 160.5,-222 166.2268,-232.5961 173.9292,-242.3673 182.5311,-251.1955\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"180.3298,-253.9363 189.9446,-258.3867 185.2037,-248.9118 180.3298,-253.9363\"/>\n</g>\n<!-- lieux&#45;&gt;accueil -->\n<g id=\"edge7\" class=\"edge\">\n<title>lieux:15&#45;&gt;accueil</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M514.5,-129.5C514.5,-129.5 544.5,-222 544.5,-222 522.6013,-251.1654 437.5439,-273.3677 366.1722,-287.3531\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"365.3587,-283.9453 356.2002,-289.2719 366.6814,-290.8193 365.3587,-283.9453\"/>\n</g>\n<!-- hopital -->\n<g id=\"node5\" class=\"node\">\n<title>hopital</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"360,-.5 360,-92.5 549,-92.5 549,-.5 360,-.5\"/>\n<text text-anchor=\"middle\" x=\"403.5\" y=\"-77.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">HOPITAL</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"447,-69.5 447,-92.5 \"/>\n<text text-anchor=\"middle\" x=\"464\" y=\"-77.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"481,-69.5 481,-92.5 \"/>\n<text text-anchor=\"middle\" x=\"498\" y=\"-77.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"515,-69.5 515,-92.5 \"/>\n<text text-anchor=\"middle\" x=\"532\" y=\"-77.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"360,-69.5 549,-69.5 \"/>\n<text text-anchor=\"middle\" x=\"378.5\" y=\"-54.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"397,-46.5 397,-69.5 \"/>\n<text text-anchor=\"middle\" x=\"415.5\" y=\"-54.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"434,-46.5 434,-69.5 \"/>\n<text text-anchor=\"middle\" x=\"472.5\" y=\"-54.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">maladie</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"511,-46.5 511,-69.5 \"/>\n<text text-anchor=\"middle\" x=\"530\" y=\"-54.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"360,-46.5 549,-46.5 \"/>\n<text text-anchor=\"middle\" x=\"370\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"380,-23.5 380,-46.5 \"/>\n<text text-anchor=\"middle\" x=\"415.5\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">infirmiere</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"451,-23.5 451,-46.5 \"/>\n<text text-anchor=\"middle\" x=\"479.5\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">docteur</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"508,-23.5 508,-46.5 \"/>\n<text text-anchor=\"middle\" x=\"528.5\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">train</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"360,-23.5 549,-23.5 \"/>\n<text text-anchor=\"middle\" x=\"374\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"388,-.5 388,-23.5 \"/>\n<text text-anchor=\"middle\" x=\"402\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"416,-.5 416,-23.5 \"/>\n<text text-anchor=\"middle\" x=\"448\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pacient</text>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"480,-.5 480,-23.5 \"/>\n<text text-anchor=\"middle\" x=\"514.5\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">retour_r</text>\n</g>\n<!-- lieux&#45;&gt;hopital -->\n<g id=\"edge6\" class=\"edge\">\n<title>lieux:7&#45;&gt;hopital</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M544.5,-187.5C570.5,-187.5 554.9692,-152.7991 544.5,-129 539.9451,-118.6457 533.3781,-109.0231 525.8358,-100.2772\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"528.3266,-97.815 518.9827,-92.8207 523.1727,-102.5518 528.3266,-97.815\"/>\n</g>\n<!-- hopital&#45;&gt;lieux -->\n<g id=\"edge8\" class=\"edge\">\n<title>hopital:15&#45;&gt;lieux</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M514.5,-.5C514.5,-.5 549,-93 549,-93 544.4732,-103.3294 537.9442,-112.9374 530.4447,-121.676\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"527.7958,-119.3862 523.6302,-129.1277 532.9616,-124.1101 527.7958,-119.3862\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7fa9bce72ee0>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Valider que la première page de la grille soit l'accueil\n",
        "pages_dict = self.get_page_dict()\n",
        "first_page_name = pages_dict.\n",
        "first_page = \n",
        "if first_page_name != 'accueil':\n",
        "  for page_name, page in pages_dict.items():\n",
        "    if page_name == 'accueil':\n",
        "\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "d={'a':1, 'b':2, 'c':3}\n",
        "t=list(d.items())\n",
        "t[0], t[2] = t[2], t[0]\n",
        "d=dict(t)\n",
        "d\n",
        "\n",
        "# for i in d:\n",
        "  # if i == 'b':\n",
        "    # print(i.index(d))\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'c': 3, 'b': 2, 'a': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.0 64-bit"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}